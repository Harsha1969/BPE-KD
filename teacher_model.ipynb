{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2014fb84-405d-43ad-8f2c-2014d04c4688",
   "metadata": {},
   "source": [
    "Dataset is accessible through: https://drive.google.com/drive/folders/13USe0gzuzmgJxKuQQqGZck3stj5WkY00?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57f8abc-a608-4009-9eb4-d697c9050dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971af11a-a4d3-418a-806f-c2f212cafd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from bpe import BayesPE  # BayesPE class\n",
    "from llm_model import LLM\n",
    "import evaluation  # Evaluation functions\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc041bf9-c205-4cb4-9fd3-0d95df6413a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define instructions\n",
    "instructions = [\n",
    "    'classify the sentiment of the Amazon review below into one of the following classes:',\n",
    "    'Categorize the sentiment of the Amazon review provided into one of the following classes:',\n",
    "    'Categorize the sentiment of the Amazon review provided into one of the given classes:',\n",
    "    'Determine the sentiment category of the given Amazon review by classifying it into one of the following classes:',\n",
    "    'Classify the sentiment of the given Amazon review into one of the following categories:',\n",
    "    'Assign the sentiment of the Amazon review provided to one of the given categories:',\n",
    "    'Categorize the sentiment of the provided Amazon review into one of the following classes:',\n",
    "    'Determine the sentiment category that best corresponds to the Amazon review provided amongst the following options:',\n",
    "    'Classify the sentiment expressed in the Amazon review below into one of the following categories:'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77eedd6e-03a3-4e4e-8b67-86d1a57128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load modified datasets\n",
    "df_train = pd.read_csv('train_modified.csv', header=None)\n",
    "df_test = pd.read_csv('test_modified.csv', header=None)\n",
    "\n",
    "n_train = 50000  \n",
    "n_in_context = 5  \n",
    "\n",
    "n_total_in_context = len(instructions) * n_in_context  \n",
    "n_test = 5000\n",
    "n_val=100\n",
    "# **Split Data**\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_test.iloc[:n_test]  \n",
    "\n",
    "# **Extract Training Data**\n",
    "gt_labels_train = df_train_actual.iloc[:, 0].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 2].values \n",
    "gt_labels_val = df_val.iloc[:, 0].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 2].values \n",
    "# **Extract Test Data (Now from `df_test`)**\n",
    "gt_labels_test = df_test_actual.iloc[:, 0].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58acd5c0-369e-493a-9566-e10b291755a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b9513f4ce54fd48651f5972750df58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: The build quality on this caliper is quite good (especially at the price). Mine has no discernible play in the mechanism, came with an extra battery and a reasonably beefy plastic case, and zeros out steadily without any display jumpiness. The unit I received is branded \"Maxwell\".Note that this caliper does *not* have fraction support in the display, and is therefore somewhat annoying to use compared to units that are only slightly more expensive.If you're completely strapped or buying these in bulk for basic uses, you won't be unhappy with your purchase. If you're a hobbyist looking for a single inexpensive but high-functionality unit, do yourself a favor and spend the extra few dollars to get one with fraction support.\n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 2:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: This item arrived with an extra piece of broken plastic inside the box, the item itself wasn't broken but the rolling piece that is use to move the caliper is loose and very low quality.\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 3:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: I am sorry to say that this caliper is not very accurate. I know for a fact that some of the beads I buy may vary slightly however not to the point this caliper says and trust me Swarovski Crystals are pretty darn accurate in size when they say 8mm it is 8mm so on these other beads I do not know if I should go up or down in number and I need the number for my program in the computer\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 4:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: If I can, I will put in 0 star for this caliper. It has no stable zero point, every time I zero it in and measure something and come back to zero, it jumps off by either 0.2 inch, 0.4 inch, or 0.6 inch. It's accuracy is worse than a 30-feet tape.I do not believe that Amazon allows this kind of product to be sold on its website.What a shame!!\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 5:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: For the price this unit was exactly what I needed. Both batteries that came with it were in fine shape and the carrying case is a nice touch. I bought this for my reloading set but have found many more uses for it. Cheap and accurate what more could you ask for?\n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 6:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: <SAMPLE_IN>\n",
      "the review is <LABEL_OUT>\n",
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:10<00:00,  9.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:08<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:09<00:00, 10.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:05<00:00, 16.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 15.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss: 18.864399676384192\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.1450173 , 0.1302915 , 0.12363394, 0.0995637 , 0.1046686 ,\n",
       "       0.07027145, 0.13994132, 0.07101653, 0.11559573], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prompt Formatting Class\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'classify the sentiment of the Amazon review below into one of the following classes:'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "# **Prepare Unique In-Context Examples Per Instruction**\n",
    "for i in range(len(instructions)):  \n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = df_in_context.iloc[:, 2].values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 0].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "\n",
    "# Optimize prompt weights\n",
    "bayespe_classifier.optimise_weights(samples_val, gt_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9bc5e-e630-459d-bd56-4972298c7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|██████████▎                                                                   | 6640/50000 [06:34<42:51, 16.86it/s]"
     ]
    }
   ],
   "source": [
    "_,probs,prompt_weights = bayespe_classifier.forward(samples_train, n_forward_passes=9)\n",
    "# Convert ensembled logits to Dirichlet parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2604da-1af2-4e56-b87d-c1805ccf0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get teacher logits and probabilities for KD\n",
    "teacher_probs,_,_ = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayespe1",
   "language": "python",
   "name": "bayespe1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
