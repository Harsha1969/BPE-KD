{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971af11a-a4d3-418a-806f-c2f212cafd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from bpe import BayesPE\n",
    "from llm_model import LLM\n",
    "import evaluation\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc041bf9-c205-4cb4-9fd3-0d95df6413a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task instructions\n",
    "instructions = [\n",
    "    'classify the sentiment of the Amazon review below into one of the following classes:',\n",
    "    'Categorize the sentiment of the Amazon review provided into one of the following classes:',\n",
    "    'Categorize the sentiment of the Amazon review provided into one of the given classes:',\n",
    "    'Determine the sentiment category of the given Amazon review by classifying it into one of the following classes:',\n",
    "    'Classify the sentiment of the given Amazon review into one of the following categories:',\n",
    "    'Assign the sentiment of the Amazon review provided to one of the given categories:',\n",
    "    'Categorize the sentiment of the provided Amazon review into one of the following classes:',\n",
    "    'Determine the sentiment category that best corresponds to the Amazon review provided amongst the following options:',\n",
    "    'Classify the sentiment expressed in the Amazon review below into one of the following categories:'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77eedd6e-03a3-4e4e-8b67-86d1a57128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load amazon reviews polarity train and test data\n",
    "df_train = pd.read_csv('train_modified.csv', header=None)\n",
    "df_test = pd.read_csv('test_modified.csv', header=None)\n",
    "n_train = 50000  \n",
    "n_in_context = 5  \n",
    "n_total_in_context = len(instructions) * n_in_context  \n",
    "n_test = 5000\n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_test.iloc[:n_test]  \n",
    "gt_labels_train = df_train_actual.iloc[:, 0].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 2].values \n",
    "gt_labels_val = df_val.iloc[:, 0].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 2].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 0].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 2].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58acd5c0-369e-493a-9566-e10b291755a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:02<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: The build quality on this caliper is quite good (especially at the price). Mine has no discernible play in the mechanism, came with an extra battery and a reasonably beefy plastic case, and zeros out steadily without any display jumpiness. The unit I received is branded \"Maxwell\".Note that this caliper does *not* have fraction support in the display, and is therefore somewhat annoying to use compared to units that are only slightly more expensive.If you're completely strapped or buying these in bulk for basic uses, you won't be unhappy with your purchase. If you're a hobbyist looking for a single inexpensive but high-functionality unit, do yourself a favor and spend the extra few dollars to get one with fraction support.\n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 2:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: This item arrived with an extra piece of broken plastic inside the box, the item itself wasn't broken but the rolling piece that is use to move the caliper is loose and very low quality.\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 3:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: I am sorry to say that this caliper is not very accurate. I know for a fact that some of the beads I buy may vary slightly however not to the point this caliper says and trust me Swarovski Crystals are pretty darn accurate in size when they say 8mm it is 8mm so on these other beads I do not know if I should go up or down in number and I need the number for my program in the computer\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 4:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: If I can, I will put in 0 star for this caliper. It has no stable zero point, every time I zero it in and measure something and come back to zero, it jumps off by either 0.2 inch, 0.4 inch, or 0.6 inch. It's accuracy is worse than a 30-feet tape.I do not believe that Amazon allows this kind of product to be sold on its website.What a shame!!\n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 5:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: For the price this unit was exactly what I needed. Both batteries that came with it were in fine shape and the carrying case is a nice touch. I bought this for my reloading set but have found many more uses for it. Cheap and accurate what more could you ask for?\n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 6:\n",
      "classify the sentiment of the Amazon review below into one of the following classes:\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: <SAMPLE_IN>\n",
      "the review is <LABEL_OUT>\n",
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:14<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:15<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:17<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:11<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:14<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:12<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 100/100 [00:14<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss: 18.82447903304606\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt formatting class for sentiment classification and initializes an LLM-based classifier\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'classify the sentiment of the Amazon review below into one of the following classes:'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "# **Prepare Unique In-Context Examples Per Instruction**\n",
    "for i in range(len(instructions)):  \n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = df_in_context.iloc[:, 2].values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 0].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "\n",
    "# Optimize prompt weights\n",
    "weights = bayespe_classifier.optimise_weights(samples_val, gt_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9bc5e-e630-459d-bd56-4972298c7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prompt weights and prompt wise probabilities on train data\n",
    "_,probs,weights = bayespe_classifier.forward(samples_train, n_forward_passes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ce68d7-4160-42ff-9ac7-c7c1c03fd123",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(probs,'amazon_probs.pt')\n",
    "torch.save(weights,'amazon_prompt_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2604da-1af2-4e56-b87d-c1805ccf0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BayesPE performance on amazon reviews polarity test data\n",
    "teacher_probs,_,_ = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8060ee2d-3758-44ef-b320-c369767106d5",
   "metadata": {},
   "source": [
    "## Evaluation on out-of-distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a09fdfb3-efd7-4d9c-bcf5-8dfa4b1b26af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task instructions for yahoo answers dataset\n",
    "instructions = [\n",
    "    'classify the question and answer below into one of the following topics:',\n",
    "    'Assign a topic label to the following question and answer from the list provided:',\n",
    "    'Determine which topic best fits the question and answer shown below:',\n",
    "    'Categorize the following Q&A under one of these topics:',\n",
    "    'Select the most appropriate topic for the question and answer pair below:',\n",
    "    'Choose the correct topic category for the given question and answer:',\n",
    "    'Identify the topic that the following question and answer belong to:',\n",
    "    'Match the question and answer below to the relevant topic:',\n",
    "    'Label the question and answer below with the most fitting topic from the list:'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ba7a036f-1795-4a66-ab76-2a6697f18e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yahoo Answers dataset\n",
    "df_train = pd.read_csv('train_yahoo.csv', header=None)\n",
    "df_test = pd.read_csv('test_yahoo.csv', header=None)\n",
    "n_train = 50000  \n",
    "n_in_context = 5  \n",
    "n_val = 100\n",
    "n_test = 5000\n",
    "n_total_in_context = len(instructions) * n_in_context\n",
    "df_train_actual = df_train.iloc[:n_train]\n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train + n_total_in_context + n_val]\n",
    "df_test_actual = df_test.iloc[:n_test]\n",
    "\n",
    "def format_prompt(q1, q2, a):\n",
    "    return \"Question: \" + q1.astype(str) + \" \" + q2.astype(str) + \"\\nAnswer: \" + a.astype(str)\n",
    "\n",
    "gt_labels_train = df_train_actual.iloc[:, 0].values.astype(int)\n",
    "samples_train = format_prompt(df_train_actual.iloc[:, 1], df_train_actual.iloc[:, 2], df_train_actual.iloc[:, 3]).values\n",
    "\n",
    "gt_labels_val = df_val.iloc[:, 0].values.astype(int)\n",
    "samples_val = format_prompt(df_val.iloc[:, 1], df_val.iloc[:, 2], df_val.iloc[:, 3]).values\n",
    "\n",
    "gt_labels_test = df_test_actual.iloc[:, 0].values.astype(int)\n",
    "samples_test = format_prompt(df_test_actual.iloc[:, 1], df_test_actual.iloc[:, 2], df_test_actual.iloc[:, 3]).values\n",
    "\n",
    "# Few-shot formatting for ensemble prompts\n",
    "for i in range(len(instructions)):\n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = format_prompt(df_in_context.iloc[:, 1], df_in_context.iloc[:, 2], df_in_context.iloc[:, 3]).values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 0].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "959831ae-4a93-41fb-af9e-14fba552065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:02<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "Question: when you talk about the volume of a gas are you refering to the volume of the molecules themselves? explain?\n",
      "Answer: No, the volume refers to the total space in which those molecules are found moving around (should be the same as the volume of the container). In any case, atoms and molecules are pretty much all empty space themselves - most of the mass is concentrated in the nucleus, but the electron cloud takes up a lot more space.\n",
      "the topic is Science & Mathematics\n",
      "\n",
      "EXAMPLE 2:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "Question: benefits of combining financial and process auditing in one department? we have departments (financial auditing and operation auditing) and we want to combine them into one internal auditing department.\n",
      "Answer: You would save on overhead costs from having to pay for equipment, utilties, and upkeep on two separate offices.\n",
      "the topic is Business & Finance\n",
      "\n",
      "EXAMPLE 3:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "Question: What Ivy League universities did the lovers of Love Story attended?  \n",
      "Answer: He studied law at Harvard; she studied music at Radcliffe\n",
      "the topic is Entertainment & Music\n",
      "\n",
      "EXAMPLE 4:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "Question: Ancient Olympics help? I need help with the ancient olympics, Please Help.\\n\\nWhy were they held?\\nWhat was in them, What games did they play?\\n\\nI will rate the best answer to  whoever answers those two questions.\n",
      "Answer: The Ancient Olympics were held in Greece up to the 1st century BC when the Romans banned them. They were held to celebrate Zeus and the Greek Gods and during the Games, an Olympic truce was established. As to what was in those Games, everything from running, to wrestling, to chariot racing\n",
      "the topic is Business & Finance\n",
      "\n",
      "EXAMPLE 5:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "Question: my search results say 1-1000 out of 80,000.. how do I get beyond the 1000, to the 80,000 ??  \n",
      "Answer: True, Google says:\\n\\n   Sorry, Google does not serve more than 1000 results for any query.\\n\\nBut here is a fast way to get way down in the list.\\n\\nFor example, go to Google and search for \"hecate\".\\n\\nScroll to the bottom of the screen and click on number 2\\n\\nNow the web address in your browser address bar will read:\\n\\nhttp: // www.google.com/ search?q=hecate &hl=en&lr=&safe=off &start=10 &sa=N\\n\\nsimply type \"9\" in front of the \"10\" in the part of the URL which reads \"start=10\"\\n\\nNow it will read \"start=910\", press Enter and ZOOM you are way  down the list!\\n\\n6sj7\n",
      "the topic is Business & Finance\n",
      "\n",
      "EXAMPLE 6:\n",
      "classify the question and answer below into one of the following topics:\n",
      "1. Society & Culture\n",
      "2. Science & Mathematics\n",
      "3. Health\n",
      "4. Education & Reference\n",
      "5. Computers & Internet\n",
      "6. Sports\n",
      "7. Business & Finance\n",
      "8. Entertainment & Music\n",
      "9. Family & Relationships\n",
      "10. Politics & Government\n",
      "\n",
      "<SAMPLE_IN>\n",
      "the topic is <LABEL_OUT>\n"
     ]
    }
   ],
   "source": [
    "# Prompt Formatting Class\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'classify the question and answer below into one of the following topics:'\n",
    "        self.CLASSES = [\n",
    "    'Society & Culture',\n",
    "    'Science & Mathematics',\n",
    "    'Health',\n",
    "    'Education & Reference',\n",
    "    'Computers & Internet',\n",
    "    'Sports',\n",
    "    'Business & Finance',\n",
    "    'Entertainment & Music',\n",
    "    'Family & Relationships',\n",
    "    'Politics & Government'\n",
    "]\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}\\n3. {}\\n4. {}\\n5. {}\\n6. {}\\n7. {}\\n8. {}\\n9. {}\\n10. {}'''.format(self.CLASSES[0],self.CLASSES[1], self.CLASSES[2], self.CLASSES[3], self.CLASSES[4], self.CLASSES[5], self.CLASSES[6], self.CLASSES[7], self.CLASSES[8], self.CLASSES[9])\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''{}\\nthe topic is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "bayespe_classifier.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "06b00aef-a646-4060-8a1a-25c1d934c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [17:01<00:00,  4.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [20:10<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [19:55<00:00,  4.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [15:46<00:00,  5.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [22:50<00:00,  3.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [17:37<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [18:44<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [17:50<00:00,  4.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 5000/5000 [18:13<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.45756762e-02 1.88207196e-05 3.39405291e-05 3.97109855e-03\n",
      "  1.35915936e-05 2.62469348e-05 3.27115393e-05 3.59431180e-03\n",
      "  9.07697825e-01 3.57699322e-05]\n",
      " [2.51664863e-01 7.29580817e-01 2.66205665e-03 1.48715499e-02\n",
      "  4.11888132e-05 1.19254624e-04 2.00581671e-05 5.67739270e-04\n",
      "  4.44848685e-04 2.76163162e-05]\n",
      " [2.57079452e-02 2.34858281e-02 1.42317237e-04 5.23723292e-02\n",
      "  3.90818353e-04 3.79506955e-03 7.04204319e-05 8.80061135e-01\n",
      "  1.38152784e-02 1.58851605e-04]\n",
      " [1.31991957e-05 1.94069460e-05 1.04723110e-05 9.99879883e-01\n",
      "  1.21276148e-05 1.01098520e-05 1.37813362e-05 1.49860088e-05\n",
      "  1.55330421e-05 1.04930465e-05]\n",
      " [9.15121512e-04 6.95151061e-03 9.83281760e-01 6.07006963e-03\n",
      "  1.04610538e-05 1.20766586e-05 1.08142086e-05 1.49965487e-05\n",
      "  2.70872762e-03 2.44550983e-05]\n",
      " [3.93673785e-01 7.35555392e-05 3.22188263e-02 8.14434073e-03\n",
      "  5.47718338e-05 4.75290514e-05 1.98641850e-02 4.46969059e-04\n",
      "  5.35088716e-01 1.03873144e-02]\n",
      " [1.29769277e-04 4.70437593e-05 1.22023357e-05 2.66148918e-03\n",
      "  4.91025607e-01 6.01815745e-05 3.41702420e-04 5.05678872e-01\n",
      "  2.94457946e-05 1.36786366e-05]\n",
      " [2.62477940e-03 4.20016843e-03 8.51369358e-01 1.32377319e-01\n",
      "  1.82649045e-04 2.36826370e-05 5.97767739e-03 1.49214563e-03\n",
      "  1.26159650e-03 4.90615747e-04]\n",
      " [2.27812072e-02 1.85294948e-01 3.35336344e-04 3.67463042e-02\n",
      "  3.27279830e-04 7.18927766e-03 7.97377847e-05 7.34816556e-01\n",
      "  1.23563081e-02 7.30373660e-05]\n",
      " [4.30082930e-03 2.64293557e-03 1.54364211e-05 1.30071303e-01\n",
      "  7.82956587e-05 8.02817589e-05 4.84214832e-05 8.62432276e-01\n",
      "  3.13470888e-04 1.67426072e-05]]\n",
      "Teacher f1-score: 0.6046280312204985, Teacher ECE: 0.210416778922081\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BayesPE performance on yahoo answers test data\n",
    "teacher_probs,yahoo_probs,weights = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fac12a86-4dcc-4e23-9e4e-4492dece0eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictive entropy\n",
    "def entropy_numpy(probs: np.ndarray) -> np.ndarray:\n",
    "    return entropy(probs, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bce5d455-6ca8-43aa-bdea-36c51ae424c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21908174 0.43992501 0.43506405 ... 0.49847439 0.53801925 0.03105501]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "probs = np.transpose(yahoo_probs, (0, 2, 1))  \n",
    "# Compute prompt wise predictive entropy\n",
    "ent_per_prompt = entropy(probs, axis=2) \n",
    "# Weighted sum of prompt wise predictive entropies\n",
    "yahoo_weighted_entropy = np.sum(ent_per_prompt * weights[None, :], axis=1)  \n",
    "print(yahoo_weighted_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c841730-ba8a-455c-b132-f23df99a403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.41573226761274634\n"
     ]
    }
   ],
   "source": [
    "# Mean predictive entropy\n",
    "print(yahoo_weighted_entropy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34907e70-334b-4f2f-b006-ca51ed075cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task instructions for sst2 dataset\n",
    "instructions = [\n",
    "    \"Classify the sentiment of the following movie review into one of the given categories.\",\n",
    "    \"Determine the emotional tone expressed in the movie review excerpt below.\",\n",
    "    \"Assign a sentiment label to the text based on its overall attitude.\",\n",
    "    \"Analyze the review and select the appropriate sentiment category it falls under.\",\n",
    "    \"What is the sentiment conveyed by this portion of the movie review? Choose from the specified classes.\",\n",
    "    \"Label the following movie review extract with its correct sentiment: positive, negative, or neutral.\",\n",
    "    \"Identify and classify the sentiment expressed in the review passage below.\",\n",
    "    \"Based on the language and tone of the review, determine the correct sentiment label.\",\n",
    "    \"Select the sentiment category that best matches the opinion expressed in the review snippet.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6cd0886-ab7a-404f-8d42-7f7bf4b23b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sst2 dataset\n",
    "df_train = pd.read_csv('train_sst2.csv')\n",
    "df_test = pd.read_csv('test_sst2.csv')\n",
    "n_train = 50000  \n",
    "n_in_context = 5  \n",
    "n_total_in_context = len(instructions) * n_in_context  \n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_test.iloc[:]  \n",
    "gt_labels_train = df_train_actual.iloc[:, 2].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 1].values \n",
    "gt_labels_val = df_val.iloc[:, 2].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 1].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 2].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 1].values \n",
    "# **Prepare Unique In-Context Examples Per Instruction**\n",
    "for i in range(len(instructions)):  \n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = df_in_context.iloc[:, 1].values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 2].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dc17e07-a5fb-48bb-b640-7830291fa58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:02<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: glow \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 2:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: a classical dramatic animated feature \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 3:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: best espionage picture \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 4:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: drag on for nearly three hours \n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 5:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: the entire point of a shaggy dog story , of course , is that it goes nowhere , and \n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 6:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: <SAMPLE_IN>\n",
      "the review is <LABEL_OUT>\n"
     ]
    }
   ],
   "source": [
    "# Prompt Formatting Class\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'Classify the sentiment of the following movie review into one of the given categories.'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "bayespe_classifier.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2a4e573-ba70-4645-a3f8-062a57fa6200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:02<00:00, 13.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:02<00:00, 14.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:03<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:04<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:05<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:04<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:03<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:05<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 872/872 [01:05<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.23062986e-05 9.99977686e-01]\n",
      " [9.97405473e-01 2.59451908e-03]\n",
      " [9.45295187e-05 9.99905463e-01]\n",
      " [5.67206895e-05 9.99943272e-01]\n",
      " [9.99415446e-01 5.84546984e-04]\n",
      " [2.96851486e-04 9.99703141e-01]\n",
      " [9.99112874e-01 8.87118647e-04]\n",
      " [9.87194502e-01 1.28054907e-02]\n",
      " [5.20410169e-05 9.99947952e-01]\n",
      " [9.99769333e-01 2.30659387e-04]]\n",
      "Teacher f1-score: 0.9541281990583655, Teacher ECE: 0.027956411242485046\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BayesPE performance on sst2 test data\n",
    "teacher_probs,sst2_probs,weights = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af234eb4-8041-43de-94b1-c4ea1ad964cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.60829570e-04 1.64556254e-02 9.37743121e-04 6.09520042e-04\n",
      " 4.75074880e-03 2.63271611e-03 6.83631451e-03 5.13098683e-02\n",
      " 5.60818755e-04 2.07374875e-03 5.60142845e-04 1.86953013e-03\n",
      " 1.22071397e-02 5.08598029e-01 2.44461213e-03 3.36788701e-04\n",
      " 6.22273778e-02 4.62060310e-04 4.52553593e-03 1.10559002e-03\n",
      " 1.55338566e-01 3.05916513e-03 1.05964496e-02 4.97998038e-04\n",
      " 3.96572236e-04 2.65204890e-03 3.27095251e-03 1.57305349e-03\n",
      " 1.86118892e-03 1.50104502e-03 1.63934612e-03 1.64008663e-03\n",
      " 3.26955232e-04 6.20146960e-02 1.17708395e-03 1.23880920e-02\n",
      " 1.80757666e-03 4.57214342e-02 5.28104270e-03 5.40318854e-04\n",
      " 8.40955629e-04 5.33746495e-04 2.01730174e-02 4.07244147e-04\n",
      " 1.47119781e-03 2.93760168e-01 4.55263360e-03 1.72930241e-03\n",
      " 3.88445090e-04 1.70793425e-03 1.39753924e-03 4.90201166e-04\n",
      " 5.89423852e-02 7.77626528e-03 1.64695951e-03 3.21488172e-04\n",
      " 2.64899620e-03 1.32829908e-02 2.94708086e-03 3.00498433e-03\n",
      " 5.56333083e-04 3.91842499e-03 7.76562098e-03 4.19299112e-04\n",
      " 5.13634788e-02 4.63707658e-03 2.77751114e-02 2.54503445e-04\n",
      " 1.00163189e-03 2.08826303e-03 2.38981081e-02 8.65638812e-04\n",
      " 5.05916868e-04 4.73318943e-03 1.58576650e-03 1.13262630e-03\n",
      " 2.15075948e-03 1.21744411e-03 1.13437385e-02 1.75209737e-03\n",
      " 1.60283951e-03 2.20576812e-03 2.63344674e-03 3.91665010e-03\n",
      " 8.01782953e-04 1.68877710e-01 1.82888466e-03 1.68162444e-02\n",
      " 4.31258313e-01 2.42030211e-03 2.03339027e-02 4.28406230e-03\n",
      " 4.38680247e-01 3.43507943e-02 1.02651690e-03 4.32298657e-01\n",
      " 1.35942269e-03 5.52951125e-04 1.74055393e-03 2.83822880e-02\n",
      " 7.04113086e-04 4.35455611e-03 2.82437215e-01 7.52756196e-04\n",
      " 9.47601544e-03 5.68503363e-03 6.97983711e-04 1.97956322e-03\n",
      " 1.89518836e-03 7.71094776e-04 9.88257818e-04 5.58135550e-03\n",
      " 7.41157020e-02 3.30076514e-03 3.44362772e-03 2.49748013e-03\n",
      " 5.07221166e-04 2.94815067e-01 2.80155680e-03 3.31626735e-01\n",
      " 4.60283171e-04 8.55552307e-03 5.81278142e-04 1.40000351e-03\n",
      " 5.75671726e-02 3.53922024e-04 2.85182524e-03 2.88853321e-03\n",
      " 4.19953278e-04 5.64820790e-04 1.93885599e-03 5.48256054e-03\n",
      " 1.23378605e-03 6.64159422e-03 1.40144581e-03 3.76705676e-03\n",
      " 3.73229881e-03 1.32049759e-03 2.31248872e-03 5.75726259e-02\n",
      " 3.89463414e-03 2.59117847e-03 5.12809029e-04 3.38575817e-01\n",
      " 2.51184366e-03 2.32770770e-03 1.89179922e-02 2.19641258e-02\n",
      " 4.89570961e-03 9.17461785e-04 8.23772297e-04 4.40307005e-04\n",
      " 3.14454552e-02 2.92717084e-03 1.00487734e-03 1.15796659e-03\n",
      " 1.79746287e-03 5.43326099e-03 3.38072700e-02 1.29658025e-01\n",
      " 2.38413588e-03 1.08932475e-02 2.31402959e-03 3.42743288e-03\n",
      " 2.28296343e-03 1.04913833e-02 2.90559719e-01 3.09969583e-02\n",
      " 4.89069938e-04 4.54492249e-04 8.49771978e-04 1.95986380e-01\n",
      " 6.86583970e-04 2.19758234e-01 8.16079800e-04 9.74609704e-03\n",
      " 2.10988576e-03 1.43674545e-01 1.20363094e-03 6.94027599e-04\n",
      " 2.15883718e-03 2.00283366e-03 1.60903412e-02 4.08469799e-01\n",
      " 2.19991411e-03 3.11162936e-04 3.82085556e-03 2.39412147e-03\n",
      " 1.33273833e-03 1.91638890e-03 1.34795508e-02 7.34599703e-04\n",
      " 5.15714047e-03 3.19797603e-03 5.30449406e-03 1.27855026e-01\n",
      " 1.31677822e-01 2.75242491e-03 3.60169448e-04 2.66592834e-02\n",
      " 3.47358213e-02 4.16099741e-02 1.61322404e-03 2.29862130e-03\n",
      " 6.85463258e-03 1.08984872e-03 1.70701399e-03 4.50686615e-04\n",
      " 9.99290459e-02 3.73606044e-03 6.21387258e-04 1.77996286e-01\n",
      " 1.48639884e-03 4.46321516e-03 1.17388645e-02 4.37170153e-03\n",
      " 5.32489123e-04 5.51266710e-02 1.21555175e-02 1.63445206e-03\n",
      " 6.18453689e-03 3.13079385e-03 9.43271305e-04 4.73500522e-01\n",
      " 4.05975687e-02 4.68581216e-03 2.71625611e-02 4.30226415e-04\n",
      " 8.11671852e-04 2.74220835e-03 6.73512432e-02 8.82581874e-04\n",
      " 1.45697058e-02 3.28796491e-03 3.21930837e-03 4.70410044e-02\n",
      " 3.24541824e-03 3.09669518e-03 1.49455096e-02 9.46835970e-04\n",
      " 6.25245323e-04 6.78828422e-03 1.90829581e-03 2.43621630e-02\n",
      " 4.15098306e-04 4.27542214e-04 1.21305490e-03 2.82530887e-03\n",
      " 8.33087375e-03 8.14837051e-02 4.71319949e-04 3.72768884e-03\n",
      " 4.96403611e-04 6.12805865e-03 1.72907837e-03 2.64956836e-03\n",
      " 2.34375758e-03 2.30417637e-03 3.17777635e-03 1.06948835e-03\n",
      " 1.39573449e-01 1.24731015e-02 1.61201909e-03 8.09644269e-04\n",
      " 4.95800768e-03 3.45542696e-03 5.32147739e-01 6.36241888e-03\n",
      " 1.61179883e-03 2.66847293e-03 7.61094339e-04 2.91609702e-03\n",
      " 6.03331145e-03 1.12548841e-01 5.19736906e-03 3.42395673e-04\n",
      " 2.52316454e-02 1.01674566e-03 6.90459749e-03 3.12406813e-01\n",
      " 8.54526078e-03 3.21192295e-03 4.03342533e-03 4.88796488e-01\n",
      " 2.74020549e-03 2.31331810e-02 1.70007074e-03 1.42411704e-03\n",
      " 6.74003608e-04 3.82072804e-01 4.18382978e-04 5.21983767e-03\n",
      " 4.05494554e-03 3.67389165e-03 5.71633626e-04 1.24736015e-01\n",
      " 3.47823197e-03 1.87964945e-02 4.33356723e-03 7.24168575e-03\n",
      " 4.48645924e-04 6.54032891e-03 3.38641883e-04 6.39725361e-04\n",
      " 7.01558594e-04 3.38869616e-03 5.83548902e-04 1.98749133e-03\n",
      " 4.92171747e-01 1.86962035e-03 7.92281949e-02 2.08679285e-04\n",
      " 1.00176424e-01 3.20420596e-04 3.54430474e-04 7.76072983e-04\n",
      " 4.09450952e-04 4.74455423e-03 2.60152935e-03 1.49834213e-03\n",
      " 6.88770231e-04 5.20516639e-01 2.88820493e-03 3.34802144e-02\n",
      " 1.94997609e-01 7.94327627e-03 2.18732749e-03 9.34539629e-04\n",
      " 5.81850640e-03 3.21577095e-03 1.55312680e-02 1.55425758e-03\n",
      " 1.84256743e-02 9.22417912e-02 6.06420758e-04 1.26734384e-03\n",
      " 1.33468712e-03 1.51175635e-03 4.74804281e-03 5.09834275e-04\n",
      " 2.46733764e-03 5.24964013e-04 2.65184334e-03 1.22443395e-03\n",
      " 9.43187172e-04 1.59326948e-03 1.34893455e-03 1.40490098e-02\n",
      " 1.16474593e-03 3.89185314e-03 2.43550394e-03 3.43230698e-03\n",
      " 8.13238068e-04 3.12748184e-04 7.80490220e-03 8.34362426e-04\n",
      " 1.29401892e-02 1.42610197e-03 9.43925671e-02 5.20515227e-04\n",
      " 5.27492895e-04 2.59111585e-03 1.03199974e-02 2.49987132e-03\n",
      " 1.62401773e-03 3.02050611e-03 7.41327680e-04 1.27091647e-01\n",
      " 1.54146126e-03 6.57483279e-04 1.92383797e-03 1.86927787e-03\n",
      " 5.96019060e-04 1.81408184e-03 2.32158875e-03 3.55042792e-03\n",
      " 1.28649246e-02 6.32772479e-02 1.73826989e-03 3.82300018e-02\n",
      " 1.36466636e-03 6.94784706e-04 3.04923624e-02 2.45942872e-04\n",
      " 7.84362440e-03 3.84734440e-01 5.57455755e-04 1.24430316e-03\n",
      " 5.46065301e-01 1.26416360e-03 3.44678525e-03 6.01274083e-03\n",
      " 2.12237143e-03 2.74191320e-04 2.64332379e-03 2.34719257e-03\n",
      " 2.75720206e-04 4.25516984e-04 2.44166835e-03 5.94631675e-01\n",
      " 6.03835641e-04 1.66204229e-02 6.24215875e-03 1.90729290e-03\n",
      " 5.15128324e-04 5.71911915e-01 3.58220796e-03 2.66024508e-03\n",
      " 1.71837145e-03 1.67643352e-03 7.53048214e-03 3.44003969e-02\n",
      " 1.54288637e-03 3.16251451e-03 4.17969058e-04 8.57439321e-04\n",
      " 1.74268862e-03 4.74249433e-04 2.81594959e-03 1.82877818e-03\n",
      " 1.69582033e-03 1.84118137e-03 3.64925603e-01 3.67562628e-02\n",
      " 2.01535700e-03 5.46024297e-03 1.04156885e-02 6.85291592e-04\n",
      " 3.88212425e-04 1.35297574e-03 3.68443790e-04 1.59579205e-02\n",
      " 3.03945128e-03 1.12728605e-03 6.31279475e-03 4.85084348e-04\n",
      " 5.00644689e-02 2.69331619e-03 5.54672539e-04 2.76997657e-04\n",
      " 3.13593793e-01 3.87687688e-03 2.17124303e-03 3.47659862e-04\n",
      " 4.51405236e-03 2.55882068e-03 8.76049059e-03 3.71233991e-01\n",
      " 4.59577410e-01 8.16083454e-03 5.67047490e-04 5.40933756e-04\n",
      " 1.65877436e-03 7.18017330e-04 5.78813725e-03 6.24840739e-04\n",
      " 1.41404712e-03 7.67090557e-04 1.14648874e-01 8.19969118e-04\n",
      " 3.04324877e-03 1.03614512e-02 4.12141049e-03 1.55971875e-03\n",
      " 8.64585789e-03 6.58008352e-03 7.77913914e-03 1.22890321e-02\n",
      " 4.95826460e-04 2.11752773e-03 6.81173771e-04 1.84935412e-03\n",
      " 3.26628353e-01 5.34904700e-04 3.22080458e-03 7.73743990e-04\n",
      " 2.41616854e-03 1.68129615e-01 1.76118198e-02 5.70341306e-04\n",
      " 8.78093826e-04 3.40733845e-01 5.12148315e-04 1.27931080e-01\n",
      " 1.44193551e-02 1.31984441e-03 1.74359607e-03 4.50747939e-03\n",
      " 3.95373146e-04 3.17274272e-03 2.25830755e-03 1.89918669e-03\n",
      " 3.35767341e-04 1.45736670e-03 3.68653485e-03 1.46454772e-02\n",
      " 1.03581851e-03 1.47087306e-03 8.12670022e-04 1.48053933e-03\n",
      " 6.03983815e-03 5.80173240e-03 1.19294207e-03 9.11224737e-04\n",
      " 2.73190602e-04 4.48608287e-02 3.65470726e-04 1.58639977e-03\n",
      " 7.14494008e-04 4.09825143e-02 9.45959111e-02 7.54953689e-04\n",
      " 6.48322744e-03 1.12880324e-01 6.69678468e-02 1.51170776e-02\n",
      " 8.15728789e-03 4.94267355e-01 9.44503596e-04 7.74391222e-03\n",
      " 6.20708391e-02 1.16508320e-03 1.32103020e-03 5.11122293e-04\n",
      " 3.90617349e-03 3.22668227e-04 2.79695338e-02 2.21013410e-03\n",
      " 9.88832967e-03 1.45228543e-03 7.55011299e-04 2.15021311e-02\n",
      " 7.13450483e-03 4.41372721e-04 4.78016525e-04 1.22577471e-03\n",
      " 6.56904383e-03 2.14961836e-03 2.66783998e-03 2.36056689e-03\n",
      " 4.79599777e-02 6.38155436e-04 2.10264688e-03 1.41341169e-03\n",
      " 9.21816989e-02 7.59151005e-03 3.54510877e-02 3.77350875e-01\n",
      " 7.40681703e-02 1.47170964e-03 1.18025700e-03 1.31563244e-03\n",
      " 2.80584030e-03 7.17884264e-04 1.26486693e-03 1.05660058e-03\n",
      " 1.88063313e-03 6.24099721e-04 5.36232602e-02 1.91902549e-02\n",
      " 1.86134978e-03 3.07000949e-01 1.72941766e-03 1.05185160e-03\n",
      " 1.57881436e-03 9.37817521e-04 1.30598196e-02 1.62370809e-03\n",
      " 1.70940638e-03 3.47124028e-04 2.11747749e-03 1.84635049e-02\n",
      " 2.26768246e-03 3.60615632e-04 2.76643042e-03 1.65025687e-02\n",
      " 1.46845321e-03 7.60383673e-04 1.95124733e-02 1.58123120e-02\n",
      " 3.23488031e-03 1.29407491e-03 1.51936663e-03 1.74628785e-03\n",
      " 2.21919255e-03 2.75621370e-03 8.92733390e-03 2.06704200e-03\n",
      " 1.08430609e-03 6.80230057e-03 1.37667203e-03 1.35252319e-03\n",
      " 3.65752357e-03 6.80721613e-04 4.08944005e-04 1.11815637e-02\n",
      " 1.33139416e-02 1.04629702e-02 1.76391314e-03 1.11359914e-03\n",
      " 2.89180742e-03 1.21590465e-02 2.66304936e-03 3.98089298e-04\n",
      " 1.14076137e-02 5.62799839e-04 1.49529910e-03 1.85693464e-02\n",
      " 1.13747507e-03 4.67269261e-02 1.52542465e-03 5.39845745e-04\n",
      " 2.83405052e-03 3.33505337e-04 5.92360088e-02 1.81996667e-02\n",
      " 3.88780106e-03 3.85564925e-03 3.32370577e-02 1.85391546e-03\n",
      " 1.44843601e-03 1.08753127e-03 1.84377560e-03 2.09018490e-03\n",
      " 1.93876539e-03 6.39100053e-04 9.84398866e-04 1.65680304e-03\n",
      " 4.51658782e-04 4.91181075e-03 1.08488739e-03 4.57442814e-03\n",
      " 1.32963364e-03 2.08316671e-03 1.18348663e-01 1.38654708e-01\n",
      " 7.91340328e-04 7.26342841e-02 7.32938765e-02 3.47032030e-03\n",
      " 5.47801931e-04 1.18262112e-03 3.04914742e-03 1.69003545e-02\n",
      " 5.33169352e-04 2.54575173e-01 2.85156859e-01 2.33005014e-03\n",
      " 1.13924701e-01 1.82833998e-03 1.14703850e-03 2.07073890e-03\n",
      " 1.84767998e-03 3.44944179e-03 2.09751353e-03 4.06945618e-03\n",
      " 2.79576114e-03 1.81653914e-03 3.51288819e-04 8.00137509e-03\n",
      " 6.77721650e-04 1.18294908e-02 1.82344425e-03 6.78658629e-03\n",
      " 4.08360521e-03 1.92165234e-02 1.02989187e-03 4.47009410e-01\n",
      " 1.07604854e-03 2.03043107e-02 4.42378600e-02 4.71743747e-04\n",
      " 5.90143059e-01 3.33516269e-02 5.70157945e-04 9.84230519e-02\n",
      " 1.30509973e-03 6.44337750e-03 2.53384111e-03 7.08669803e-04\n",
      " 2.63661926e-02 1.89695745e-03 2.78824298e-03 3.30685403e-01\n",
      " 1.78495168e-01 6.68216901e-03 8.78500190e-04 1.28216198e-03\n",
      " 1.78016211e-02 2.95455030e-03 2.08125574e-03 3.84461250e-01\n",
      " 1.45463892e-01 3.12458814e-03 1.66450434e-02 2.38838851e-03\n",
      " 1.29431533e-03 2.05256195e-02 2.67219898e-03 1.94092234e-02\n",
      " 3.47728188e-03 1.59664627e-03 3.86770149e-03 3.65962522e-03\n",
      " 8.89625050e-04 1.77494136e-03 5.30653996e-03 1.71824581e-01\n",
      " 4.56134042e-04 1.46997459e-03 3.57089922e-02 1.45174789e-03\n",
      " 2.35405103e-03 3.99489946e-03 4.44854930e-04 1.43984938e-03\n",
      " 1.44582855e-03 2.31239465e-03 3.48793238e-04 3.14213962e-03\n",
      " 9.43922407e-04 8.21335958e-04 1.10973163e-02 6.27451227e-04\n",
      " 2.33056890e-03 2.10925711e-03 8.85118831e-04 2.58775060e-03\n",
      " 2.94019851e-02 6.41715779e-04 1.40675793e-03 9.06790297e-02\n",
      " 1.55504538e-03 3.35124624e-03 5.64639241e-03 4.30923229e-03\n",
      " 1.63672951e-02 6.00712163e-04 3.71143900e-04 3.50097816e-03\n",
      " 7.28529429e-04 7.84513566e-02 1.77941172e-01 2.48385854e-03\n",
      " 1.21822917e-03 1.21593554e-03 7.74597511e-04 1.66547092e-03\n",
      " 4.91514329e-03 6.30263748e-02 2.86811255e-03 1.86836338e-03\n",
      " 6.00293134e-02 1.04317447e-03 4.13320937e-03 3.78291657e-04\n",
      " 2.63194022e-03 2.56677157e-03 7.00429648e-04 2.40251854e-03\n",
      " 4.47215707e-01 9.16832467e-04 4.16936094e-04 7.63371384e-03\n",
      " 3.69288707e-03 9.81877029e-02 4.18641252e-02 5.40043082e-04\n",
      " 9.38859426e-03 2.92368649e-04 1.79897468e-03 4.11358787e-03\n",
      " 4.41622879e-02 2.16805384e-03 1.74754868e-03 2.32717356e-02\n",
      " 2.43314773e-03 1.96612692e-01 3.30177009e-04 2.32429508e-03\n",
      " 5.00032468e-01 2.01211532e-03 1.15551881e-01 8.71487761e-04\n",
      " 2.18799071e-03 8.00251853e-04 6.47548538e-03 1.42306242e-03\n",
      " 7.93520798e-04 1.36982273e-03 4.31273106e-03 1.26301578e-02\n",
      " 1.66474553e-03 1.53561713e-01 5.72884671e-04 1.20097808e-03\n",
      " 1.60626380e-02 3.82728319e-03 8.24302302e-03 3.20424289e-04\n",
      " 3.34053588e-03 7.00584642e-02 2.61105940e-02 1.17313853e-02\n",
      " 5.81463395e-03 3.84850840e-01 5.61971228e-04 2.85307975e-04\n",
      " 2.60094728e-04 5.20998454e-04 4.27501537e-04 1.13086870e-02\n",
      " 4.74945368e-01 1.30607551e-03 4.12456254e-03 2.09392271e-04\n",
      " 1.27397670e-03 6.96713706e-04 1.36499406e-03 2.94405247e-01\n",
      " 5.11240989e-04 6.82190435e-04 2.58136717e-03 3.38901644e-02\n",
      " 6.24503828e-03 3.40389698e-04 2.45221781e-04 3.07635430e-03\n",
      " 2.45922002e-03 3.29683490e-03 3.74190038e-01 2.05721491e-03\n",
      " 3.61964505e-03 1.50260292e-03 1.44826493e-03 4.41799247e-04\n",
      " 2.10100689e-03 2.08853045e-03 1.39871517e-02 2.43637862e-03\n",
      " 1.75126032e-03 4.27525439e-03 4.55745197e-03 6.12720576e-03\n",
      " 2.38665257e-03 2.48850067e-03 3.29539174e-01 3.73537410e-01\n",
      " 5.23205719e-04 1.91496925e-02 8.66230659e-03 2.41426002e-01\n",
      " 7.59929226e-02 1.80530128e-02 8.39752652e-03 5.34464746e-04\n",
      " 1.76343145e-01 6.29794276e-04 1.66554818e-03 1.38214311e-03\n",
      " 6.78874475e-03 3.05818066e-03 7.67309776e-02 4.62385745e-02\n",
      " 8.88968524e-04 4.51084776e-01 5.65360150e-02 1.43665934e-03\n",
      " 2.30689335e-03 2.46918928e-03 2.00857620e-03 9.22183433e-04]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "probs = np.transpose(sst2_probs, (0, 2, 1))  \n",
    "# Compute prompt wise predictive entropy\n",
    "ent_per_prompt = entropy(probs, axis=2) \n",
    "# Weighted sum of prompt wise predictive entropies\n",
    "sst2_weighted_entropy = np.sum(ent_per_prompt * weights[None, :], axis=1)  \n",
    "print(sst2_weighted_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a90522d2-54e7-48f4-8c94-fd42f3f8c1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034164633291940354\n"
     ]
    }
   ],
   "source": [
    "# Mean predictive entropy\n",
    "print(sst2_weighted_entropy.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e403cd2-41c6-4628-8126-a7eba29804d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task instructions for yahoo answers dataset\n",
    "instructions = [\n",
    "    \"Is the following Youtube comment spam?\",\n",
    "    \"Determine whether the given Youtube comment is spam.\",\n",
    "    \"Classify the following Youtube comment as spam or not.\",\n",
    "    \"Check if the Youtube comment below is considered spam.\",\n",
    "    \"Decide if the given Youtube comment is spam.\",\n",
    "    \"Is this Youtube comment a form of spam?\",\n",
    "    \"Evaluate whether this Youtube comment qualifies as spam.\",\n",
    "    \"Identify if the following comment on Youtube is spam.\",\n",
    "    \"Judge whether the Youtube comment should be flagged as spam.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67de6f09-1c60-442a-97df-37edf2d566af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load youtube comments dataset\n",
    "df_train = pd.read_csv('youtube.csv')\n",
    "n_train = 1100  \n",
    "n_in_context = 5 \n",
    "n_total_in_context = len(instructions) * n_in_context  \n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_train.iloc[n_train+n_total_in_context+n_val:]  \n",
    "gt_labels_train = df_train_actual.iloc[:, 4].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 3].values \n",
    "gt_labels_val = df_val.iloc[:, 4].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 3].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 4].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 3].values \n",
    "\n",
    "# **Prepare Unique In-Context Examples Per Instruction**\n",
    "for i in range(len(instructions)):  \n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = df_in_context.iloc[:, 3].values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 4].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a93af0c-eecb-4684-8a0e-95f86fcadb9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:02<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: Check out my music niggas﻿\n",
      "the comment is spam\n",
      "\n",
      "EXAMPLE 2:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: Check out this video on YouTube:﻿\n",
      "the comment is spam\n",
      "\n",
      "EXAMPLE 3:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: Check out this funny video &quot;Cereal Box Knocks out Baby&quot; on my channel.﻿\n",
      "the comment is spam\n",
      "\n",
      "EXAMPLE 4:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: Subscribe to me if u think &quot;swag&quot; is fucking stupid﻿\n",
      "the comment is spam\n",
      "\n",
      "EXAMPLE 5:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: Tuto to subscribe to my channel because you should sign up for 17 l please thank you I&#39;d do anything for you to sign up a lot of good video I usually do!﻿\n",
      "the comment is spam\n",
      "\n",
      "EXAMPLE 6:\n",
      "Is the following Youtube comment spam?\n",
      "1. not spam\n",
      "2. spam\n",
      "\n",
      "comment: <SAMPLE_IN>\n",
      "the comment is <LABEL_OUT>\n"
     ]
    }
   ],
   "source": [
    "# Prompt Formatting Class\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'Is the following Youtube comment spam?'\n",
    "        self.CLASSES = ['not spam', 'spam']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['ham', 'spam'], ['0', '1']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''comment: {}\\nthe comment is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "bayespe_classifier.weights = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "962f3511-ec1d-4288-a1ce-c96828b05e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:55<00:00, 12.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [01:04<00:00, 11.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:55<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [01:03<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:59<00:00, 11.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:56<00:00, 12.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:57<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [00:59<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 711/711 [01:02<00:00, 11.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.89566912e-02 9.41043301e-01]\n",
      " [6.21771073e-04 9.99378221e-01]\n",
      " [6.94467871e-02 9.30553205e-01]\n",
      " [7.40624053e-04 9.99259368e-01]\n",
      " [7.40624053e-04 9.99259368e-01]\n",
      " [9.94847618e-01 5.15237435e-03]\n",
      " [9.92957754e-01 7.04223902e-03]\n",
      " [1.36637034e-04 9.99863356e-01]\n",
      " [1.05120554e-01 8.94879439e-01]\n",
      " [1.05120554e-01 8.94879439e-01]]\n",
      "Teacher f1-score: 0.8787151493993874, Teacher ECE: 0.03464491665363312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BayesPE performance on youtube comments test data\n",
    "teacher_probs,youtube_probs,weights = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "665081cd-2645-4460-86b2-67261b1fa916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17063244 0.00496051 0.10939222 0.00578485 0.00578485 0.02790974\n",
      " 0.03794173 0.00131676 0.19368446 0.19368446 0.40600933 0.11768295\n",
      " 0.00288808 0.06727981 0.15339182 0.46094292 0.23556086 0.19368446\n",
      " 0.05676766 0.22681406 0.47486896 0.08808524 0.0527278  0.03188253\n",
      " 0.05257225 0.40524636 0.02928423 0.41103096 0.03644919 0.02442789\n",
      " 0.12086012 0.16785526 0.50101336 0.02607865 0.02900213 0.2764365\n",
      " 0.05623508 0.37179636 0.15153049 0.24571285 0.27515651 0.36238353\n",
      " 0.41266723 0.06552536 0.0101001  0.20329124 0.01613747 0.36238353\n",
      " 0.08537064 0.00562075 0.0300261  0.10909997 0.04952306 0.28148751\n",
      " 0.26081753 0.30855909 0.10693868 0.10104218 0.06010398 0.34865794\n",
      " 0.02135728 0.09563375 0.18358281 0.07654769 0.44275371 0.07444779\n",
      " 0.39614169 0.01578395 0.10193236 0.25555387 0.4316324  0.03085098\n",
      " 0.01659718 0.0941828  0.06494452 0.11752309 0.02388175 0.00192674\n",
      " 0.46965758 0.55860553 0.11829509 0.04635694 0.12029956 0.17905823\n",
      " 0.27586304 0.17544742 0.02277353 0.12116817 0.02297473 0.03239593\n",
      " 0.25902107 0.28958351 0.13196447 0.04723483 0.18317285 0.16851919\n",
      " 0.25809701 0.0403355  0.38640432 0.31380743 0.1667467  0.30963354\n",
      " 0.36238353 0.0347714  0.12666491 0.01733104 0.02161097 0.02669804\n",
      " 0.05054936 0.29988445 0.11029658 0.13588837 0.0968475  0.11622696\n",
      " 0.11200478 0.09377939 0.01210123 0.10216984 0.15209488 0.00767449\n",
      " 0.01814914 0.30527317 0.08423801 0.07489492 0.45569952 0.44710537\n",
      " 0.01259184 0.21448649 0.09128709 0.01271811 0.36238353 0.12002738\n",
      " 0.43064701 0.29538304 0.26584058 0.15840567 0.36238353 0.38640432\n",
      " 0.14856036 0.20097196 0.01659718 0.06299349 0.13067299 0.05914643\n",
      " 0.21729396 0.01070817 0.15893567 0.30927152 0.33776624 0.13119907\n",
      " 0.49770888 0.01306308 0.00814932 0.02904091 0.15659264 0.38640432\n",
      " 0.46467223 0.00392676 0.36238353 0.3666009  0.09057202 0.13835237\n",
      " 0.06719454 0.26359499 0.38531313 0.08174458 0.19878621 0.00404049\n",
      " 0.09666036 0.19368446 0.13297162 0.23172253 0.0138203  0.01425604\n",
      " 0.1504941  0.01860384 0.01860384 0.1377963  0.04123076 0.36238353\n",
      " 0.00816573 0.17615523 0.03024945 0.02164993 0.43244638 0.22278424\n",
      " 0.30579502 0.08060897 0.03747407 0.30282537 0.02744428 0.24475237\n",
      " 0.13595729 0.43890663 0.03496233 0.15797871 0.07255763 0.46998837\n",
      " 0.07255763 0.01108518 0.40597613 0.14315719 0.13722465 0.16670453\n",
      " 0.36238353 0.38830271 0.22576824 0.17078769 0.34292816 0.23652326\n",
      " 0.03448049 0.32337738 0.45825422 0.50452029 0.04491902 0.11144638\n",
      " 0.33561442 0.56858717 0.0780299  0.18291111 0.10329867 0.27682957\n",
      " 0.42229758 0.44884255 0.04198314 0.24170604 0.01200967 0.03844814\n",
      " 0.52737748 0.43848628 0.14171626 0.1577287  0.06220095 0.33114239\n",
      " 0.10660237 0.12362069 0.21926811 0.04015915 0.20664976 0.42976196\n",
      " 0.10321039 0.00201778 0.26206363 0.03788767 0.1162657  0.03766617\n",
      " 0.08741564 0.01920464 0.16397904 0.29776958 0.15062799 0.50452029\n",
      " 0.03326582 0.18195949 0.55298895 0.45976771 0.20611205 0.08157358\n",
      " 0.13319353 0.15452239 0.03290728 0.30400093 0.22946888 0.01819445\n",
      " 0.15776175 0.35118271 0.22016409 0.07973665 0.05963224 0.36238353\n",
      " 0.13433262 0.09115384 0.41207339 0.50452029 0.10780061 0.02927081\n",
      " 0.08487233 0.00425939 0.29933515 0.34512542 0.04616648 0.50452029\n",
      " 0.03373214 0.04370784 0.10400824 0.10980457 0.49060111 0.05148167\n",
      " 0.05813801 0.27397188 0.19089824 0.12737046 0.02805823 0.22773872\n",
      " 0.34027264 0.01093071 0.04466496 0.07401509 0.08979971 0.05782632\n",
      " 0.31864952 0.13563236 0.03157437 0.25806731 0.06078657 0.26226168\n",
      " 0.16892738 0.02562319 0.04456439 0.07404456 0.00408429 0.04701033\n",
      " 0.23994664 0.56769955 0.29986738 0.34763499 0.11850369 0.10753935\n",
      " 0.16836324 0.01687649 0.3349372  0.3372418  0.04241151 0.20485339\n",
      " 0.1387114  0.08165829 0.07088028 0.18386021 0.02022035 0.01303484\n",
      " 0.28503439 0.09305919 0.0443717  0.09476377 0.04790026 0.41207081\n",
      " 0.05500885 0.21235084 0.35617767 0.09937466 0.35694225 0.01144806\n",
      " 0.14233295 0.14233295 0.17269654 0.30678075 0.18266176 0.23900739\n",
      " 0.02273725 0.10165586 0.04356535 0.39870401 0.37752393 0.02495805\n",
      " 0.12384317 0.404201   0.04058748 0.22122423 0.1312659  0.12727803\n",
      " 0.25307682 0.04768776 0.30858704 0.29201113 0.37719585 0.49476017\n",
      " 0.42371942 0.07318963 0.05371891 0.01483106 0.30858704 0.20471541\n",
      " 0.42011343 0.26747129 0.03007113 0.02705495 0.05023056 0.36238353\n",
      " 0.02871701 0.0301876  0.07137171 0.04756824 0.0100507  0.02665858\n",
      " 0.09960948 0.21031822 0.03166498 0.10674319 0.01871672 0.18143324\n",
      " 0.07007926 0.08554629 0.01021716 0.00247916 0.45192113 0.34588393\n",
      " 0.44519612 0.22418278 0.02153277 0.15548371 0.45545548 0.36238353\n",
      " 0.19696492 0.54613343 0.37444244 0.16830228 0.24251143 0.08775118\n",
      " 0.011346   0.4676887  0.0685846  0.20339389 0.23415782 0.02899823\n",
      " 0.10265958 0.03604896 0.43189018 0.32364797 0.09722292 0.11872059\n",
      " 0.26657558 0.26568173 0.44877311 0.01260176 0.13449489 0.02820883\n",
      " 0.30858704 0.05826809 0.04440912 0.12124228 0.20319315 0.06899759\n",
      " 0.01849892 0.011346   0.27908308 0.4012296  0.04145844 0.49906312\n",
      " 0.35907854 0.34722701 0.03677258 0.01894163 0.28108783 0.01575793\n",
      " 0.01417644 0.35943378 0.4675453  0.14557979 0.01369583 0.26334174\n",
      " 0.01837969 0.08968453 0.04437831 0.14403131 0.12815068 0.30858704\n",
      " 0.45230576 0.4676887  0.44828166 0.03031014 0.31764837 0.03734027\n",
      " 0.43074996 0.04358108 0.39247446 0.3953114  0.00995132 0.0765568\n",
      " 0.17817212 0.09302002 0.11386067 0.02624624 0.01564728 0.54927837\n",
      " 0.13806479 0.45694723 0.18594213 0.21283049 0.02010892 0.02611975\n",
      " 0.05130762 0.02044335 0.11026619 0.18943094 0.02039438 0.41791294\n",
      " 0.38275763 0.0512764  0.48006695 0.17736029 0.3467862  0.36238353\n",
      " 0.28898122 0.34660205 0.11677382 0.00387894 0.00900184 0.00294871\n",
      " 0.1696915  0.35605191 0.0041066  0.29201113 0.16065409 0.00236095\n",
      " 0.32849879 0.31620929 0.00225002 0.36238353 0.00166556 0.35259828\n",
      " 0.1794674  0.15611266 0.40561002 0.15235734 0.02309842 0.19650133\n",
      " 0.31994157 0.14020678 0.17063244 0.06727981 0.02706057 0.01888663\n",
      " 0.3728853  0.20399739 0.04077423 0.05954665 0.08987879 0.0070724\n",
      " 0.37054249 0.09101561 0.18788438 0.00517574 0.00192174 0.0070724\n",
      " 0.00944077 0.00429737 0.11757595 0.10463715 0.13026882 0.2503067\n",
      " 0.12131524 0.00429737 0.006674   0.006674   0.45892021 0.07810117\n",
      " 0.00429737 0.11384654 0.46403811 0.18803173 0.29764493 0.25641943\n",
      " 0.12114997 0.12114997 0.08867662 0.2635157  0.02413579 0.38661346\n",
      " 0.0921498  0.24594143 0.27000036 0.17618929 0.15717872 0.03640356\n",
      " 0.1217103  0.01323784 0.42079309 0.01332742 0.33747286 0.01689127\n",
      " 0.29917144 0.00989288 0.10420891 0.10045863 0.02980643 0.1217103\n",
      " 0.07042584 0.03734027 0.12228936 0.31036186 0.07042584 0.1091158\n",
      " 0.0158411  0.0403764  0.02114709 0.35908797 0.03824763 0.03288289\n",
      " 0.10250292 0.05030635 0.2808119  0.22290838 0.36698936 0.24595988\n",
      " 0.18878874 0.00465353 0.00643263 0.40597613 0.02999512 0.11144638\n",
      " 0.00383585 0.03844814 0.02413579 0.06315541 0.0960096  0.1217103\n",
      " 0.04472611 0.37215203 0.06607345 0.04046495 0.02056107 0.01003252\n",
      " 0.02833569 0.01412325 0.0826149  0.06055441 0.09209025 0.14530846\n",
      " 0.44219725 0.47292765 0.0463302  0.01584876 0.35692873 0.10814548\n",
      " 0.04409165 0.01867795 0.17516372 0.1217103  0.03227757 0.44632502\n",
      " 0.00230955 0.1666638  0.00494003 0.00262721 0.13123243 0.35400804\n",
      " 0.25915624 0.2200696  0.01663111 0.04659171 0.18066338 0.3834477\n",
      " 0.14786945 0.3834477  0.26941563 0.00409008 0.3834477  0.37343149\n",
      " 0.20941997 0.00367301 0.00233062 0.40242777 0.00356493 0.32105218\n",
      " 0.33061353 0.33061353 0.26575828 0.00701195 0.07847957 0.29703642\n",
      " 0.13628357 0.01810095 0.01810095 0.10190093 0.32100246 0.01335263\n",
      " 0.18878874 0.1728903  0.26575828 0.32678838 0.22290838 0.22290838\n",
      " 0.18878874 0.18878874 0.08955007 0.22290838 0.51162815 0.09487613\n",
      " 0.01795165 0.0035505  0.0035505  0.21996272 0.30769932 0.35610376\n",
      " 0.01335263 0.43180323 0.43219785 0.30839355 0.41387296 0.03734027\n",
      " 0.02813855 0.14708533 0.43210292 0.38068993 0.02325032 0.011824\n",
      " 0.21355222 0.50167429 0.00579391 0.30769932 0.01440679 0.01440679\n",
      " 0.01440679 0.20898508 0.04003401 0.01883054 0.02080653 0.04728867\n",
      " 0.03734027 0.44236709 0.07160176]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "\n",
    "probs = np.transpose(youtube_probs, (0, 2, 1))  \n",
    "# Compute prompt wise predictive entropy\n",
    "ent_per_prompt = entropy(probs, axis=2) \n",
    "# Weighted sum of prompt wise predictive entropies\n",
    "youtube_weighted_entropy = np.sum(ent_per_prompt * weights[None, :], axis=1)  \n",
    "print(youtube_weighted_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad35b08-46d3-455c-9579-2d77a8502e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17132808865700833\n"
     ]
    }
   ],
   "source": [
    "# Mean predictive entropy\n",
    "print(youtube_weighted_entropy.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
