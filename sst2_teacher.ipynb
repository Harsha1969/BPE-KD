{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a57f8abc-a608-4009-9eb4-d697c9050dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "971af11a-a4d3-418a-806f-c2f212cafd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from bpe import BayesPE  # BayesPE class\n",
    "from llm_model import LLM\n",
    "import evaluation  # Evaluation functions\n",
    "import constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc041bf9-c205-4cb4-9fd3-0d95df6413a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define task instructions\n",
    "instructions = [\n",
    "    \"Classify the sentiment of the following movie review into one of the given categories.\",\n",
    "    \"Determine the emotional tone expressed in the movie review excerpt below.\",\n",
    "    \"Assign a sentiment label to the text based on its overall attitude.\",\n",
    "    \"Analyze the review and select the appropriate sentiment category it falls under.\",\n",
    "    \"What is the sentiment conveyed by this portion of the movie review? Choose from the specified classes.\",\n",
    "    \"Label the following movie review extract with its correct sentiment: positive, negative, or neutral.\",\n",
    "    \"Identify and classify the sentiment expressed in the review passage below.\",\n",
    "    \"Based on the language and tone of the review, determine the correct sentiment label.\",\n",
    "    \"Select the sentiment category that best matches the opinion expressed in the review snippet.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77eedd6e-03a3-4e4e-8b67-86d1a57128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SST2 train and test data\n",
    "df_train = pd.read_csv('train_sst2.csv')\n",
    "df_test = pd.read_csv('test_sst2.csv')\n",
    "n_train = 50000  \n",
    "n_in_context = 5  \n",
    "\n",
    "n_total_in_context = len(instructions) * n_in_context  \n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_test.iloc[:]  \n",
    "\n",
    "gt_labels_train = df_train_actual.iloc[:, 2].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 1].values \n",
    "gt_labels_val = df_val.iloc[:, 2].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 1].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 2].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 1].values \n",
    "\n",
    "# **Prepare Unique In-Context Examples Per Instruction**\n",
    "for i in range(len(instructions)):  \n",
    "    start_idx = i * n_in_context\n",
    "    end_idx = (i + 1) * n_in_context\n",
    "    df_in_context = df_in_context_base.iloc[start_idx:end_idx]\n",
    "\n",
    "    samples_in_context_i = df_in_context.iloc[:, 1].values\n",
    "    gt_labels_in_context_i = df_in_context.iloc[:, 2].values.astype(int)\n",
    "\n",
    "    if i == 0:\n",
    "        samples_in_context = np.expand_dims(samples_in_context_i, axis=1)\n",
    "        gt_labels_in_context = np.expand_dims(gt_labels_in_context_i, axis=1)\n",
    "    else:\n",
    "        samples_in_context = np.concatenate((samples_in_context, np.expand_dims(samples_in_context_i, axis=1)), axis=1)\n",
    "        gt_labels_in_context = np.concatenate((gt_labels_in_context, np.expand_dims(gt_labels_in_context_i, axis=1)), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58acd5c0-369e-493a-9566-e10b291755a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56ccd06febf44ae68e5a57d934310aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: glow \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 2:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: a classical dramatic animated feature \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 3:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: best espionage picture \n",
      "the review is positive\n",
      "\n",
      "EXAMPLE 4:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: drag on for nearly three hours \n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 5:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: the entire point of a shaggy dog story , of course , is that it goes nowhere , and \n",
      "the review is negative\n",
      "\n",
      "EXAMPLE 6:\n",
      "Classify the sentiment of the following movie review into one of the given categories.\n",
      "1. negative\n",
      "2. positive\n",
      "\n",
      "review: <SAMPLE_IN>\n",
      "the review is <LABEL_OUT>\n",
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 14.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:06<00:00, 14.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:07<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss: 10.080135552103378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.11324611, 0.06342231, 0.10655718, 0.06697492, 0.07831271,\n",
       "       0.09093669, 0.07694805, 0.11141872, 0.29218334], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a prompt formatting class for sentiment classification and initializes an LLM-based classifier\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'Classify the sentiment of the following movie review into one of the given categories.'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize BayesPE (Teacher Model)\n",
    "bayespe_classifier = BayesPE(\n",
    "    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", \n",
    "    prompt_formatting=prompt_formatting,\n",
    "    instructions=instructions, \n",
    "    few_shot_texts_sets=samples_in_context, \n",
    "    few_shot_labels_sets=gt_labels_in_context, \n",
    "    use_reduced_precision=True\n",
    ")\n",
    "\n",
    "# Print example prompt\n",
    "bayespe_classifier.print_prompt_example()\n",
    "\n",
    "# Optimize prompt weights\n",
    "bayespe_classifier.optimise_weights(samples_val, gt_labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ee9bc5e-e630-459d-bd56-4972298c7304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:13<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:38<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:16<00:00, 27.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [31:04<00:00, 26.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:56<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:32<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:57<00:00, 26.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:31<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50000/50000 [30:56<00:00, 26.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get prompt weights and prompt wise probabilities on train data\n",
    "_,probs,weights = bayespe_classifier.forward(samples_train, n_forward_passes=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89122371-8ebb-4caa-8469-5618b749da62",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(probs,'sst2_probs.pt')\n",
    "torch.save(weights,'sst2_prompt_weights.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb2604da-1af2-4e56-b87d-c1805ccf0186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 1 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:00<00:00, 14.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 2 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:04<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 3 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:02<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 4 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:05<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 5 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:05<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 6 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:03<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 7 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:05<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 8 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:03<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference for promt 9 out of 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 872/872 [01:05<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference time: 577.3881 seconds\n",
      "[[2.15308646e-05 9.99978484e-01]\n",
      " [9.96954942e-01 3.04507307e-03]\n",
      " [8.22373726e-05 9.99917778e-01]\n",
      " [5.46948111e-05 9.99945320e-01]\n",
      " [9.99416429e-01 5.83586077e-04]\n",
      " [2.76974521e-04 9.99723040e-01]\n",
      " [9.99103096e-01 8.96918986e-04]\n",
      " [9.87049482e-01 1.29505324e-02]\n",
      " [5.05681623e-05 9.99949447e-01]\n",
      " [9.99733136e-01 2.66879291e-04]]\n",
      "Teacher f1-score: 0.9552751705390573, Teacher ECE: 0.029035435989499092\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BayesPE performance on sst2 test data\n",
    "start = torch.cuda.Event(enable_timing=True)\n",
    "end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "start.record()\n",
    "teacher_probs,_,_ = bayespe_classifier.forward(samples_test, n_forward_passes=9)\n",
    "end.record()\n",
    "\n",
    "# Wait for the events to be recorded\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# Report in seconds\n",
    "elapsed_time_ms = start.elapsed_time(end)  # in milliseconds\n",
    "elapsed_time_sec = elapsed_time_ms / 1000  # convert to seconds\n",
    "\n",
    "print(f\"Inference time: {elapsed_time_sec:.4f} seconds\")\n",
    "print(teacher_probs[:10, :])\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, teacher_probs, metric='ece')\n",
    "print('Teacher f1-score: {}, Teacher ECE: {}'.format(f1_score, ece))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
