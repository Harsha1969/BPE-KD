{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d255a80-cf9b-460a-ba1f-498cc632fc0f",
   "metadata": {},
   "source": [
    "## Student Model(with dirichlet output) training and evaluation on Amazon reviews polarity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa8e92a3-db78-4ab0-ae77-bc397147e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46ae2666-72c7-41ec-86fa-dd1c4a4e60b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from llm_classifier_modified import LLMClassifier\n",
    "from llm_model_modified import LLM\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy.stats import dirichlet\n",
    "import evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874b21ca-81c8-4a9c-82de-d5f7b93e4f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Amazon reviews polarity train and test data\n",
    "df_train = pd.read_csv('train_amazon.csv', header=None)\n",
    "df_test = pd.read_csv('test_amazon.csv', header=None)\n",
    "\n",
    "n_train = 10000\n",
    "n_in_context = 5  \n",
    "n_total_in_context = len(df_train) * n_in_context  \n",
    "n_test = 5000\n",
    "n_val = 100\n",
    "\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train + n_total_in_context + n_val]\n",
    "df_test_actual = df_test.iloc[:n_test]  \n",
    "\n",
    "gt_labels_train = df_train_actual.iloc[:, 0].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 2].values \n",
    "gt_labels_val = df_val.iloc[:, 0].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 2].values \n",
    "\n",
    "gt_labels_test = df_test_actual.iloc[:, 0].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 2].values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2111c18a-1e30-4b96-b43e-ce5b20e05e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06a651c32a98499b8e5c2c4b9bcf7269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,221,312 || all params: 7,262,244,864 || trainable%: 0.1958\n"
     ]
    }
   ],
   "source": [
    "# Define a prompt formatting class for sentiment classification and initializes an LLM-based classifier\n",
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        # Best instruction from BayesPE teacher i.e. instruction with highest weight\n",
    "        self.INSTRUCTION = 'classify the sentiment of the Amazon review below into one of the following classes:'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "llm = LLM(model_name=\"mistralai/Mistral-7B-Instruct-v0.3\", use_reduced_precision=True,use_lora=True)\n",
    "prompt_formatting = PromptFormatting()\n",
    "classifier = LLMClassifier(model=llm, prompt_formatting=prompt_formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c64a5382-f643-4443-8df4-ad36279ecace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher predictions and weights\n",
    "probs = torch.load(\"amazon_probs.pt\", weights_only=False)\n",
    "weights = torch.load(\"amazon_prompt_weights.pt\", weights_only=False)\n",
    "if isinstance(probs, np.ndarray):\n",
    "    probs = torch.tensor(probs, dtype=torch.float32, device=llm.device)\n",
    "if isinstance(weights, np.ndarray):\n",
    "    weights = torch.tensor(weights, dtype=torch.float32, device=llm.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5e1396a-bf7c-420c-992f-e8a8ef6ee676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Dirichlet-based distillation loss\n",
    "import torch\n",
    "\n",
    "def dirichlet_loss(alpha, probs, weights):\n",
    "\n",
    "    alpha_0 = torch.sum(alpha, dim=1, keepdim=True)                      \n",
    "    log_gamma_alpha_0 = torch.lgamma(alpha_0)                           \n",
    "    log_gamma_alpha_c = torch.lgamma(alpha).sum(dim=1, keepdim=True)   \n",
    "\n",
    "    alpha_expanded = alpha.unsqueeze(-1)                                \n",
    "\n",
    "    weighted_log_probs = (alpha_expanded - 1) * torch.log(probs + 1e-8) \n",
    "\n",
    "    class_sum = weighted_log_probs.sum(dim=1)                           \n",
    "\n",
    "    if weights.ndim == 1:\n",
    "        weights = weights.unsqueeze(1)                                   \n",
    "    weights_broadcasted = weights.T.expand(probs.shape[0], -1)          \n",
    "    \n",
    "    weighted_terms = class_sum * weights_broadcasted                  \n",
    "\n",
    "    prompt_sum = weighted_terms.sum(dim=1, keepdim=True)               \n",
    "\n",
    "    loss = -(log_gamma_alpha_0 - log_gamma_alpha_c + prompt_sum).mean()\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08ce7fc6-8234-47c7-a786-1d2e92374b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of model on Amazon reviews polarity test data\n",
    "def evaluate():\n",
    "    def dirichlet_to_prob(alpha):\n",
    "        return alpha / alpha.sum(dim=1, keepdim=True) \n",
    "    \n",
    "    \n",
    "    class TestDirichletDataset(Dataset):\n",
    "        def __init__(self, samples, n_samples):\n",
    "            self.samples = samples\n",
    "            self.n_samples = n_samples\n",
    "    \n",
    "        def __len__(self):\n",
    "            return self.n_samples\n",
    "    \n",
    "        def __getitem__(self, idx):\n",
    "            return self.samples[idx]\n",
    "    \n",
    "    llm.model.eval()\n",
    "    test_dataset = TestDirichletDataset(samples_test, n_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False) \n",
    "    \n",
    "    def get_test_alpha(test_dataloader, classifier):\n",
    "        all_alpha = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for batch_samples in test_dataloader:\n",
    "                alpha_batch = classifier.soft_labels_batch(input_texts=batch_samples)\n",
    "                all_alpha.append(alpha_batch)\n",
    "    \n",
    "        return torch.cat(all_alpha, dim=0) \n",
    "    \n",
    "    alpha_test = get_test_alpha(test_dataloader, classifier)\n",
    "    stu_probs = dirichlet_to_prob(alpha_test)\n",
    "    stu_probs=stu_probs.cpu().numpy()\n",
    "    f1_score = evaluation.compute_metric(gt_labels_test, stu_probs, metric='f1')\n",
    "    ece = evaluation.compute_metric(gt_labels_test, stu_probs, metric='ece')\n",
    "    print('Student f1-score: {}, Student ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3396e346-a531-48d0-80f4-b2e54cef9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class DirichletDataset(Dataset):\n",
    "    def __init__(self, samples, num_samples):\n",
    "        self.samples = samples\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0161c507-a518-4714-aa86-aae058fb4ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: -1564.08486405015\n",
      "Student f1-score: 0.951456341839787, Student ECE: 0.010912657715380192\n",
      "Epoch 2/10, Loss: -2205.8668997883797\n",
      "Student f1-score: 0.9585356323742725, Student ECE: 0.01002875529229641\n",
      "Epoch 3/10, Loss: -2415.1293152570724\n",
      "Student f1-score: 0.9579417981779905, Student ECE: 0.005028365179896355\n",
      "Epoch 4/10, Loss: -2402.583825945854\n",
      "Student f1-score: 0.9569887121176082, Student ECE: 0.009572663344442844\n",
      "Epoch 5/10, Loss: -2564.2673350572586\n",
      "Student f1-score: 0.9591458699117983, Student ECE: 0.018178431317210197\n",
      "Epoch 6/10, Loss: -2664.221682071686\n",
      "Student f1-score: 0.9575293015765765, Student ECE: 0.021279077976942062\n",
      "Epoch 7/10, Loss: -2782.1060552597046\n",
      "Student f1-score: 0.9585468720130468, Student ECE: 0.019260089844465256\n",
      "Epoch 8/10, Loss: -2873.131416320801\n",
      "Student f1-score: 0.959346726324044, Student ECE: 0.02085147425532341\n",
      "Epoch 9/10, Loss: -2956.709189891815\n",
      "Student f1-score: 0.9601576571517145, Student ECE: 0.022752856835722923\n",
      "Epoch 10/10, Loss: -3015.910043478012\n",
      "Student f1-score: 0.9589625722243715, Student ECE: 0.02252080664038658\n"
     ]
    }
   ],
   "source": [
    "# Train student model with teacher predictions and evaluate after each epoch on test data\n",
    "def train_student(samples_train, probs, weights, num_epochs=10, learning_rate=1e-5, batch_size=32):\n",
    "    dataset = DirichletDataset(samples_train, len(samples_train))\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    optimizer = optim.AdamW(filter(lambda p: p.requires_grad, llm.model.parameters()), lr=learning_rate)\n",
    "    llm.model.train()  \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        llm.model.train()\n",
    "        for batch_idx, (batch_samples, batch_indices) in enumerate(dataloader, start=1):\n",
    "            batch_indices = batch_indices.to(llm.device)\n",
    "\n",
    "            batch_probs = probs[batch_indices] \n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            alpha = classifier.soft_labels_batch(input_texts=batch_samples)\n",
    "            alpha = torch.clamp(alpha, min=1e-3)\n",
    "            loss = dirichlet_loss(alpha, batch_probs, weights)\n",
    "          \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 1000 == 0:\n",
    "                    print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(dataloader)}\")\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss}\")\n",
    "        evaluate()\n",
    "train_student(samples_train, probs, weights, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25be328-0068-45e2-96fe-b5972ea293b5",
   "metadata": {},
   "source": [
    "## Evaluation on out-of-distribution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91f1fb83-6212-4abd-8f6b-60cb352a5656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Yahoo Answers dataset\n",
    "df_train = pd.read_csv('train_yahoo.csv', header=None)\n",
    "df_test = pd.read_csv('test_yahoo.csv', header=None)\n",
    "\n",
    "n_train = 10000  \n",
    "n_in_context = 5  \n",
    "n_val = 100\n",
    "n_test = 5000\n",
    "\n",
    "# Split data\n",
    "df_train_actual = df_train.iloc[:n_train]\n",
    "df_test_actual = df_test.iloc[:n_test]\n",
    "\n",
    "# Format function for prompts\n",
    "def format_prompt(q1, q2, a):\n",
    "    return \"Question: \" + q1.astype(str) + \" \" + q2.astype(str) + \"\\nAnswer: \" + a.astype(str)\n",
    "\n",
    "# Extract training data\n",
    "gt_labels_train = df_train_actual.iloc[:, 0].values.astype(int)\n",
    "samples_train = format_prompt(df_train_actual.iloc[:, 1], df_train_actual.iloc[:, 2], df_train_actual.iloc[:, 3]).values\n",
    "\n",
    "gt_labels_test = df_test_actual.iloc[:, 0].values.astype(int)\n",
    "samples_test = format_prompt(df_test_actual.iloc[:, 1], df_test_actual.iloc[:, 2], df_test_actual.iloc[:, 3]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d7a12f5-f571-4980-b810-01c568b41534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'classify the question and answer below into one of the following topics:'\n",
    "        self.CLASSES = [\n",
    "    'Society & Culture',\n",
    "    'Science & Mathematics',\n",
    "    'Health',\n",
    "    'Education & Reference',\n",
    "    'Computers & Internet',\n",
    "    'Sports',\n",
    "    'Business & Finance',\n",
    "    'Entertainment & Music',\n",
    "    'Family & Relationships',\n",
    "    'Politics & Government'\n",
    "]\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}\\n3. {}\\n4. {}\\n5. {}\\n6. {}\\n7. {}\\n8. {}\\n9. {}\\n10. {}'''.format(self.CLASSES[0],self.CLASSES[1], self.CLASSES[2], self.CLASSES[3], self.CLASSES[4], self.CLASSES[5], self.CLASSES[6], self.CLASSES[7], self.CLASSES[8], self.CLASSES[9])\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''{}\\nthe topic is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "classifier = LLMClassifier(model=llm, prompt_formatting=prompt_formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64bb6fba-d5e0-4c06-85ee-c497400c5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of model on Yahoo answers test data\n",
    "def dirichlet_to_prob(alpha):\n",
    "    return alpha / alpha.sum(dim=1, keepdim=True) \n",
    "\n",
    "\n",
    "class DirichletDataset(Dataset):\n",
    "    def __init__(self, samples, n_samples):\n",
    "        self.samples = samples\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "llm.model.eval()\n",
    "test_dataset = DirichletDataset(samples_test, n_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False) \n",
    "\n",
    "def get_test_alpha(test_dataloader, classifier):\n",
    "    all_alpha = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_samples in test_dataloader:\n",
    "            alpha_batch = classifier.soft_labels_batch(input_texts=batch_samples)\n",
    "            all_alpha.append(alpha_batch)\n",
    "\n",
    "    return torch.cat(all_alpha, dim=0) \n",
    "\n",
    "yahoo_alpha_test = get_test_alpha(test_dataloader, classifier)\n",
    "stu_probs = dirichlet_to_prob(yahoo_alpha_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9fd0837-77f2-4028-bab0-630c39fc98bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student f1-score: 0.5545621356087371, Student ECE: 0.2955533266067505\n"
     ]
    }
   ],
   "source": [
    "import evaluation  \n",
    "stu_probs=stu_probs.cpu().numpy()\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, stu_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, stu_probs, metric='ece')\n",
    "print('Student f1-score: {}, Student ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2f907f67-561e-46c7-a78f-a0069fc90192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the predictive entropy by sampling from Dirichlet distribution\n",
    "def dirichlet_entropy(alpha: torch.Tensor, n_samples: int = 1000) -> torch.Tensor:\n",
    "\n",
    "    batch_size, num_classes = alpha.shape\n",
    "    \n",
    "    alpha_expanded = alpha.unsqueeze(1).expand(batch_size, n_samples, num_classes)\n",
    "    \n",
    "    samples = torch.distributions.Dirichlet(alpha_expanded).sample()  \n",
    "    \n",
    "    entropy_samples = -torch.sum(samples * torch.log(samples + 1e-10), dim=2) \n",
    "    \n",
    "    entropy_estimate = entropy_samples.mean(dim=1) \n",
    "    \n",
    "    return entropy_estimate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f854f0ac-96a4-4396-a504-7826026281ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.1386, 2.0383, 2.0178,  ..., 2.0230, 2.0151, 1.8256], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predictive entropy on yahoo answers test data\n",
    "ent_yahoo = dirichlet_entropy(yahoo_alpha_test)\n",
    "print(ent_yahoo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a496ed6b-d34d-4150-9c83-ae798a37cdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.0286, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Mean predictive entropy\n",
    "print(ent_yahoo.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e8a3dfc-ed37-42f8-a8e2-764f73300bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sst2 dataset\n",
    "df_train = pd.read_csv('train_sst2.csv')\n",
    "df_test = pd.read_csv('test_sst2.csv')\n",
    "n_train = 10000  \n",
    "n_in_context = 5  \n",
    "n_total_in_context = 9 * n_in_context  \n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_test_actual = df_test.iloc[:]  \n",
    "gt_labels_train = df_train_actual.iloc[:, 2].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 1].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 2].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 1].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50b81337-ced0-4306-a793-4c21c7371ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'Select the sentiment category that best matches the opinion expressed in the review snippet.'\n",
    "        self.CLASSES = ['negative', 'positive']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['neg', 'pos'], ['1', '2']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''review: {}\\nthe review is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "classifier = LLMClassifier(model=llm, prompt_formatting=prompt_formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bf7e7d54-9ef9-40e6-94c2-7cbfb4b2f6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of model on sst2 test data\n",
    "def dirichlet_to_prob(alpha):\n",
    "    return alpha / alpha.sum(dim=1, keepdim=True) \n",
    "\n",
    "\n",
    "class DirichletDataset(Dataset):\n",
    "    def __init__(self, samples, n_samples):\n",
    "        self.samples = samples\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "llm.model.eval()\n",
    "test_dataset = DirichletDataset(samples_test, 872)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False) \n",
    "\n",
    "def get_test_alpha(test_dataloader, classifier):\n",
    "    all_alpha = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_samples in test_dataloader:\n",
    "            alpha_batch = classifier.soft_labels_batch(input_texts=batch_samples)\n",
    "            all_alpha.append(alpha_batch)\n",
    "\n",
    "    return torch.cat(all_alpha, dim=0) \n",
    "\n",
    "sst2_alpha_test = get_test_alpha(test_dataloader, classifier)\n",
    "stu_probs = dirichlet_to_prob(sst2_alpha_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d9ccefa-d477-46b9-8335-93e580588666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student f1-score: 0.9506771110804181, Student ECE: 0.016975531354546547\n"
     ]
    }
   ],
   "source": [
    "import evaluation  \n",
    "stu_probs=stu_probs.cpu().numpy()\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, stu_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, stu_probs, metric='ece')\n",
    "print('Student f1-score: {}, Student ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7248decc-f75d-4261-9a02-ca008cbc05db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0164, 0.0517, 0.0154, 0.0157, 0.0231, 0.0180, 0.2753, 0.3825, 0.0158,\n",
      "        0.0355, 0.0156, 0.0451, 0.1752, 0.5100, 0.0200, 0.0157, 0.4975, 0.0159,\n",
      "        0.0945, 0.0563, 0.5022, 0.1333, 0.1261, 0.0152, 0.0161, 0.1583, 0.0990,\n",
      "        0.0397, 0.0338, 0.0192, 0.0167, 0.0422, 0.0156, 0.2825, 0.0335, 0.1814,\n",
      "        0.0156, 0.3833, 0.0521, 0.0157, 0.0160, 0.0167, 0.0852, 0.0161, 0.0297,\n",
      "        0.4942, 0.0300, 0.0178, 0.0167, 0.0335, 0.0232, 0.0162, 0.5056, 0.0647,\n",
      "        0.0200, 0.0168, 0.0657, 0.3615, 0.0377, 0.0257, 0.0170, 0.1691, 0.0453,\n",
      "        0.0166, 0.4944, 0.1473, 0.5023, 0.0154, 0.0184, 0.0193, 0.2788, 0.0158,\n",
      "        0.0161, 0.4915, 0.0223, 0.0398, 0.0518, 0.0854, 0.2397, 0.0187, 0.0178,\n",
      "        0.0464, 0.0653, 0.0161, 0.0170, 0.1716, 0.0356, 0.0625, 0.4656, 0.0178,\n",
      "        0.2267, 0.1086, 0.5044, 0.4945, 0.0150, 0.1523, 0.0332, 0.0162, 0.0196,\n",
      "        0.2057, 0.0176, 0.0575, 0.4990, 0.0165, 0.1202, 0.1625, 0.0155, 0.0383,\n",
      "        0.0339, 0.0173, 0.0588, 0.0570, 0.0287, 0.0319, 0.0959, 0.1077, 0.0154,\n",
      "        0.5006, 0.0499, 0.5037, 0.0200, 0.0906, 0.0218, 0.0194, 0.0260, 0.0158,\n",
      "        0.0283, 0.1065, 0.0155, 0.0167, 0.0926, 0.1233, 0.0445, 0.0925, 0.0212,\n",
      "        0.1267, 0.1435, 0.0226, 0.0215, 0.2315, 0.1575, 0.0657, 0.0189, 0.3292,\n",
      "        0.0462, 0.0390, 0.0266, 0.2959, 0.1359, 0.0187, 0.0174, 0.0157, 0.1170,\n",
      "        0.0395, 0.0311, 0.0263, 0.0163, 0.0267, 0.3036, 0.4924, 0.1582, 0.1080,\n",
      "        0.0654, 0.0405, 0.1876, 0.1499, 0.5047, 0.1878, 0.0158, 0.0159, 0.0165,\n",
      "        0.5059, 0.0154, 0.4992, 0.0162, 0.1061, 0.1205, 0.3745, 0.0218, 0.0155,\n",
      "        0.0474, 0.0215, 0.1300, 0.3237, 0.0365, 0.0148, 0.0180, 0.0488, 0.0204,\n",
      "        0.0704, 0.1299, 0.0149, 0.2321, 0.0235, 0.1031, 0.5186, 0.2395, 0.0590,\n",
      "        0.0157, 0.1716, 0.3354, 0.0382, 0.0341, 0.0321, 0.0555, 0.0787, 0.0171,\n",
      "        0.0158, 0.3258, 0.0320, 0.0157, 0.4997, 0.0219, 0.1638, 0.2019, 0.0210,\n",
      "        0.0158, 0.3675, 0.2996, 0.0168, 0.0269, 0.0363, 0.0163, 0.4820, 0.2738,\n",
      "        0.0183, 0.2272, 0.0154, 0.0532, 0.0532, 0.0831, 0.0161, 0.2214, 0.0837,\n",
      "        0.1124, 0.2170, 0.0967, 0.0372, 0.3078, 0.0172, 0.0165, 0.2515, 0.0725,\n",
      "        0.0657, 0.0148, 0.0161, 0.0153, 0.0286, 0.1601, 0.5009, 0.0152, 0.0659,\n",
      "        0.0157, 0.0753, 0.0226, 0.0328, 0.0252, 0.0632, 0.0282, 0.0164, 0.5090,\n",
      "        0.1022, 0.0498, 0.0155, 0.1461, 0.1624, 0.5079, 0.2223, 0.0206, 0.0261,\n",
      "        0.0174, 0.0567, 0.0501, 0.4988, 0.1165, 0.0154, 0.1384, 0.0150, 0.2124,\n",
      "        0.2417, 0.0174, 0.1231, 0.1410, 0.4721, 0.0716, 0.1073, 0.0555, 0.0159,\n",
      "        0.0163, 0.5060, 0.0145, 0.2382, 0.3136, 0.0217, 0.0152, 0.3854, 0.0980,\n",
      "        0.5095, 0.0694, 0.0179, 0.0160, 0.1801, 0.0167, 0.0165, 0.0158, 0.1729,\n",
      "        0.0149, 0.0157, 0.4899, 0.0164, 0.3528, 0.0158, 0.4927, 0.0158, 0.0166,\n",
      "        0.0293, 0.0158, 0.0376, 0.0443, 0.0499, 0.0163, 0.5075, 0.0297, 0.5029,\n",
      "        0.4972, 0.1715, 0.0340, 0.0163, 0.1862, 0.0174, 0.4094, 0.0794, 0.0434,\n",
      "        0.2097, 0.0143, 0.0212, 0.0154, 0.0239, 0.1160, 0.0162, 0.0241, 0.0163,\n",
      "        0.0696, 0.0215, 0.0165, 0.0165, 0.0191, 0.2605, 0.0207, 0.0743, 0.0498,\n",
      "        0.3484, 0.0182, 0.0159, 0.0298, 0.0437, 0.0978, 0.0358, 0.5032, 0.0269,\n",
      "        0.0162, 0.0494, 0.0261, 0.0739, 0.0196, 0.0679, 0.0157, 0.3990, 0.0240,\n",
      "        0.0158, 0.0529, 0.0166, 0.0150, 0.0221, 0.0251, 0.4154, 0.0286, 0.2395,\n",
      "        0.0440, 0.2634, 0.0489, 0.0158, 0.5050, 0.0158, 0.1127, 0.5138, 0.0157,\n",
      "        0.0217, 0.4986, 0.0201, 0.0435, 0.2141, 0.0493, 0.0158, 0.0258, 0.0391,\n",
      "        0.0155, 0.0167, 0.0216, 0.5127, 0.0153, 0.0490, 0.1668, 0.0655, 0.0160,\n",
      "        0.5004, 0.0162, 0.0840, 0.1062, 0.0201, 0.0173, 0.1428, 0.0343, 0.0416,\n",
      "        0.0152, 0.0157, 0.0222, 0.0162, 0.0743, 0.1164, 0.0207, 0.0357, 0.5108,\n",
      "        0.3080, 0.0295, 0.0238, 0.0285, 0.0152, 0.0161, 0.0193, 0.0155, 0.0999,\n",
      "        0.1265, 0.0159, 0.1004, 0.0172, 0.4007, 0.0157, 0.0161, 0.0156, 0.2589,\n",
      "        0.1251, 0.0285, 0.0157, 0.0594, 0.0184, 0.0591, 0.3586, 0.5024, 0.1373,\n",
      "        0.0161, 0.0159, 0.0195, 0.0169, 0.1034, 0.0161, 0.0378, 0.0157, 0.0856,\n",
      "        0.0161, 0.0204, 0.2465, 0.0792, 0.0254, 0.2873, 0.1249, 0.0205, 0.0313,\n",
      "        0.0160, 0.0198, 0.0162, 0.0305, 0.5032, 0.0158, 0.0603, 0.0145, 0.0748,\n",
      "        0.4995, 0.4963, 0.0150, 0.0157, 0.5194, 0.0160, 0.4873, 0.4640, 0.0171,\n",
      "        0.0202, 0.0935, 0.0156, 0.0245, 0.0261, 0.0254, 0.0153, 0.0193, 0.1137,\n",
      "        0.0245, 0.1010, 0.0476, 0.0155, 0.0170, 0.0525, 0.1563, 0.0196, 0.0204,\n",
      "        0.0141, 0.1661, 0.0148, 0.0488, 0.0162, 0.2061, 0.5123, 0.0155, 0.1826,\n",
      "        0.4477, 0.2601, 0.0713, 0.2071, 0.5002, 0.0165, 0.0293, 0.1819, 0.0270,\n",
      "        0.0780, 0.0161, 0.0169, 0.0150, 0.2716, 0.1263, 0.2613, 0.0268, 0.0153,\n",
      "        0.1956, 0.5126, 0.0165, 0.0157, 0.0231, 0.1417, 0.0175, 0.0207, 0.0314,\n",
      "        0.4966, 0.0158, 0.1067, 0.0297, 0.3213, 0.1133, 0.4876, 0.5101, 0.1013,\n",
      "        0.0210, 0.0253, 0.0713, 0.0455, 0.0297, 0.0197, 0.0210, 0.0366, 0.0155,\n",
      "        0.5082, 0.1382, 0.0207, 0.4987, 0.0358, 0.0157, 0.0246, 0.0214, 0.1941,\n",
      "        0.0253, 0.0410, 0.0154, 0.0376, 0.3572, 0.0427, 0.0162, 0.0294, 0.2141,\n",
      "        0.0192, 0.0169, 0.1134, 0.0572, 0.0195, 0.0174, 0.0261, 0.0651, 0.0438,\n",
      "        0.0832, 0.0738, 0.0279, 0.0181, 0.1387, 0.0227, 0.0218, 0.0481, 0.0154,\n",
      "        0.0155, 0.1446, 0.1853, 0.1040, 0.0184, 0.0199, 0.0280, 0.0689, 0.0359,\n",
      "        0.0154, 0.2680, 0.0167, 0.0199, 0.4890, 0.0324, 0.0675, 0.0207, 0.0161,\n",
      "        0.0681, 0.0157, 0.4945, 0.1643, 0.0380, 0.0611, 0.3395, 0.0199, 0.0335,\n",
      "        0.0177, 0.0167, 0.0501, 0.0735, 0.0165, 0.0157, 0.0328, 0.0153, 0.0688,\n",
      "        0.0159, 0.2210, 0.0280, 0.0169, 0.0570, 0.1903, 0.0280, 0.3615, 0.0280,\n",
      "        0.0775, 0.0156, 0.0193, 0.0206, 0.0161, 0.0160, 0.2158, 0.5013, 0.0986,\n",
      "        0.5016, 0.0208, 0.0232, 0.0427, 0.0220, 0.0367, 0.0344, 0.2578, 0.1323,\n",
      "        0.0612, 0.0167, 0.1970, 0.0158, 0.2729, 0.0301, 0.0206, 0.0151, 0.0253,\n",
      "        0.0252, 0.4605, 0.0239, 0.1207, 0.2076, 0.0155, 0.5015, 0.0533, 0.0163,\n",
      "        0.3125, 0.0221, 0.0199, 0.0165, 0.0219, 0.1523, 0.0323, 0.0345, 0.4950,\n",
      "        0.5185, 0.0178, 0.0158, 0.0205, 0.1085, 0.0324, 0.0200, 0.5123, 0.2681,\n",
      "        0.0304, 0.2896, 0.0235, 0.0155, 0.2988, 0.0551, 0.3925, 0.0491, 0.0422,\n",
      "        0.0245, 0.0893, 0.0414, 0.0586, 0.1868, 0.3857, 0.0155, 0.0945, 0.4966,\n",
      "        0.0292, 0.0551, 0.0860, 0.0152, 0.0276, 0.0303, 0.0165, 0.0152, 0.0396,\n",
      "        0.0162, 0.0173, 0.1761, 0.0160, 0.1143, 0.0153, 0.0160, 0.0229, 0.5163,\n",
      "        0.0169, 0.0201, 0.3597, 0.0212, 0.0713, 0.0666, 0.1503, 0.5065, 0.0185,\n",
      "        0.0156, 0.0157, 0.0168, 0.5050, 0.3806, 0.0225, 0.5070, 0.0211, 0.0167,\n",
      "        0.0218, 0.0639, 0.2865, 0.0321, 0.0962, 0.4177, 0.0156, 0.0260, 0.0161,\n",
      "        0.0381, 0.0425, 0.0157, 0.0322, 0.5049, 0.0215, 0.0157, 0.2172, 0.1333,\n",
      "        0.2145, 0.0186, 0.0157, 0.0322, 0.0160, 0.0285, 0.0905, 0.3018, 0.2644,\n",
      "        0.0267, 0.2130, 0.0226, 0.2852, 0.0156, 0.0482, 0.4743, 0.0988, 0.5086,\n",
      "        0.0176, 0.0451, 0.0164, 0.0763, 0.0374, 0.0158, 0.0218, 0.0450, 0.1065,\n",
      "        0.0532, 0.1799, 0.0158, 0.0187, 0.1582, 0.0494, 0.0967, 0.0155, 0.0243,\n",
      "        0.4391, 0.1438, 0.0220, 0.1288, 0.5159, 0.0161, 0.0162, 0.0160, 0.0163,\n",
      "        0.0154, 0.1666, 0.4581, 0.0249, 0.0207, 0.0157, 0.0224, 0.0173, 0.0215,\n",
      "        0.4971, 0.0167, 0.0167, 0.0226, 0.5119, 0.1918, 0.0155, 0.0159, 0.0291,\n",
      "        0.1486, 0.0638, 0.1500, 0.0875, 0.1301, 0.0337, 0.0176, 0.0151, 0.0964,\n",
      "        0.1099, 0.2815, 0.0649, 0.0196, 0.0456, 0.1670, 0.2134, 0.0191, 0.0490,\n",
      "        0.4252, 0.4967, 0.0159, 0.1226, 0.1184, 0.2378, 0.2668, 0.3818, 0.1924,\n",
      "        0.0170, 0.4545, 0.0151, 0.0170, 0.0158, 0.0280, 0.0163, 0.2065, 0.3889,\n",
      "        0.0211, 0.4535, 0.0986, 0.0439, 0.0304, 0.1186, 0.0429, 0.0156],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predictive entropy on sst2 test data\n",
    "ent_sst2 = dirichlet_entropy(sst2_alpha_test)\n",
    "print(ent_sst2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "06bfe23b-8999-4dde-8630-2108b6dfc598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1146, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(ent_sst2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff6c3e-9e53-464f-8001-1a5fa9c4dc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "05a4e65e-9871-4e2d-ac01-a58a1f7e6d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load youtube comments dataset\n",
    "df_train = pd.read_csv('youtube.csv')\n",
    "n_train = 1100  \n",
    "n_in_context = 5 \n",
    "n_total_in_context = 9 * n_in_context  \n",
    "n_val=100\n",
    "df_train_actual = df_train.iloc[:n_train] \n",
    "df_in_context_base = df_train.iloc[n_train:n_train + n_total_in_context]\n",
    "df_val = df_train.iloc[n_train + n_total_in_context:n_train+n_total_in_context+n_val]\n",
    "df_test_actual = df_train.iloc[n_train+n_total_in_context+n_val:]  \n",
    "gt_labels_train = df_train_actual.iloc[:, 4].values.astype(int) \n",
    "samples_train = df_train_actual.iloc[:, 3].values \n",
    "gt_labels_val = df_val.iloc[:, 4].values.astype(int) \n",
    "samples_val = df_val.iloc[:, 3].values \n",
    "gt_labels_test = df_test_actual.iloc[:, 4].values.astype(int)\n",
    "samples_test = df_test_actual.iloc[:, 3].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f046703-ad7e-4dd7-9291-4f83da2cbe3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptFormatting(object):\n",
    "    def __init__(self):\n",
    "        self.INSTRUCTION = 'Judge whether the Youtube comment should be flagged as spam.'\n",
    "        self.CLASSES = ['not spam', 'spam']\n",
    "        self.CLASSES_FOR_MATCHING = [self.CLASSES, ['ham', 'spam'], ['0', '1']]\n",
    "        self.CLASSES_TEXT = '''1. {}\\n2. {}'''.format(self.CLASSES[0], self.CLASSES[1])\n",
    "\n",
    "    def format_instruction(self, instruction):\n",
    "        return '''{}\\n{}\\n'''.format(instruction, self.CLASSES_TEXT)\n",
    "\n",
    "    def format_content(self, content):\n",
    "        return '''comment: {}\\nthe comment is '''.format(content)\n",
    "\n",
    "prompt_formatting = PromptFormatting()\n",
    "classifier = LLMClassifier(model=llm, prompt_formatting=prompt_formatting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78b22df9-6de2-4049-988e-06f44c1a516e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance of model on youtube comments test data\n",
    "def dirichlet_to_prob(alpha):\n",
    "    return alpha / alpha.sum(dim=1, keepdim=True) \n",
    "\n",
    "\n",
    "class DirichletDataset(Dataset):\n",
    "    def __init__(self, samples, n_samples):\n",
    "        self.samples = samples\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "llm.model.eval()\n",
    "test_dataset = DirichletDataset(samples_test, 711)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False) \n",
    "\n",
    "def get_test_alpha(test_dataloader, classifier):\n",
    "    all_alpha = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_samples in test_dataloader:\n",
    "            alpha_batch = classifier.soft_labels_batch(input_texts=batch_samples)\n",
    "            all_alpha.append(alpha_batch)\n",
    "\n",
    "    return torch.cat(all_alpha, dim=0) \n",
    "\n",
    "youtube_alpha_test = get_test_alpha(test_dataloader, classifier)\n",
    "stu_probs = dirichlet_to_prob(youtube_alpha_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "10149b39-a363-40f0-a994-420f17594b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student f1-score: 0.5224537771227076, Student ECE: 0.14621475338935852\n"
     ]
    }
   ],
   "source": [
    "import evaluation  \n",
    "stu_probs=stu_probs.cpu().numpy()\n",
    "f1_score = evaluation.compute_metric(gt_labels_test, stu_probs, metric='f1')\n",
    "ece = evaluation.compute_metric(gt_labels_test, stu_probs, metric='ece')\n",
    "print('Student f1-score: {}, Student ECE: {}'.format(f1_score, ece))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "648ab9a2-3d8a-4323-8c82-8fc2a367a12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5304, 0.6640, 0.5778, 0.6527, 0.6513, 0.4010, 0.4197, 0.4753, 0.5635,\n",
      "        0.5617, 0.4277, 0.4687, 0.6423, 0.6407, 0.4868, 0.5873, 0.6159, 0.5650,\n",
      "        0.3918, 0.4491, 0.6012, 0.6071, 0.6593, 0.5052, 0.6575, 0.4285, 0.6543,\n",
      "        0.5418, 0.6603, 0.6568, 0.4886, 0.4058, 0.5742, 0.4640, 0.6565, 0.5254,\n",
      "        0.5735, 0.5169, 0.4534, 0.5153, 0.5023, 0.4488, 0.4186, 0.4121, 0.6528,\n",
      "        0.4436, 0.6571, 0.4449, 0.3824, 0.5734, 0.3325, 0.3367, 0.5573, 0.4536,\n",
      "        0.5345, 0.5636, 0.6524, 0.6364, 0.5444, 0.4319, 0.6348, 0.6579, 0.4182,\n",
      "        0.4703, 0.5836, 0.4301, 0.6283, 0.4295, 0.6406, 0.4463, 0.4902, 0.5741,\n",
      "        0.4492, 0.6432, 0.6519, 0.5506, 0.4316, 0.5154, 0.3295, 0.4721, 0.4323,\n",
      "        0.4964, 0.6419, 0.4410, 0.6502, 0.6170, 0.4659, 0.6415, 0.6274, 0.3363,\n",
      "        0.5445, 0.5906, 0.5664, 0.4536, 0.4660, 0.3626, 0.5363, 0.6487, 0.3917,\n",
      "        0.5114, 0.5735, 0.4504, 0.4441, 0.3016, 0.4395, 0.6676, 0.3281, 0.5830,\n",
      "        0.5075, 0.4550, 0.6255, 0.6217, 0.6578, 0.6282, 0.6453, 0.4137, 0.3917,\n",
      "        0.6380, 0.5174, 0.6500, 0.6506, 0.3737, 0.6031, 0.6301, 0.4397, 0.4848,\n",
      "        0.5448, 0.5118, 0.4499, 0.6578, 0.4544, 0.3715, 0.4746, 0.4488, 0.5755,\n",
      "        0.5530, 0.4514, 0.3828, 0.5655, 0.5173, 0.4520, 0.4862, 0.5325, 0.6558,\n",
      "        0.4992, 0.4308, 0.5066, 0.5110, 0.5431, 0.5437, 0.5099, 0.6709, 0.6614,\n",
      "        0.4535, 0.4092, 0.3850, 0.5239, 0.6284, 0.4466, 0.4488, 0.4407, 0.5232,\n",
      "        0.6613, 0.6407, 0.4835, 0.4618, 0.4688, 0.6476, 0.3795, 0.5680, 0.4685,\n",
      "        0.5851, 0.6643, 0.4232, 0.5574, 0.6388, 0.6403, 0.5996, 0.5605, 0.4631,\n",
      "        0.6345, 0.4541, 0.6558, 0.6525, 0.4710, 0.5610, 0.4885, 0.5209, 0.6043,\n",
      "        0.5076, 0.4379, 0.5020, 0.5367, 0.4605, 0.5393, 0.4257, 0.6686, 0.5485,\n",
      "        0.6675, 0.6626, 0.4604, 0.4117, 0.4679, 0.5645, 0.4532, 0.5164, 0.5306,\n",
      "        0.6137, 0.5247, 0.5166, 0.4442, 0.5673, 0.3917, 0.4019, 0.3576, 0.3046,\n",
      "        0.4584, 0.6147, 0.6616, 0.5726, 0.6141, 0.5535, 0.6349, 0.3803, 0.5064,\n",
      "        0.6097, 0.4468, 0.6187, 0.5225, 0.4895, 0.6640, 0.5384, 0.3210, 0.4713,\n",
      "        0.4865, 0.5903, 0.3918, 0.4216, 0.3880, 0.4630, 0.6470, 0.5601, 0.3088,\n",
      "        0.5934, 0.3762, 0.4419, 0.5913, 0.5640, 0.5900, 0.5417, 0.6650, 0.4049,\n",
      "        0.4096, 0.4382, 0.4860, 0.5064, 0.4227, 0.6550, 0.6361, 0.4726, 0.4176,\n",
      "        0.4846, 0.4766, 0.4234, 0.5124, 0.4725, 0.5451, 0.5949, 0.6636, 0.4525,\n",
      "        0.6680, 0.5591, 0.4177, 0.3987, 0.4020, 0.6449, 0.5550, 0.6613, 0.5190,\n",
      "        0.5169, 0.4553, 0.4046, 0.4599, 0.5870, 0.4450, 0.5165, 0.6089, 0.6474,\n",
      "        0.4038, 0.5640, 0.4667, 0.5189, 0.3561, 0.5726, 0.4478, 0.4085, 0.6316,\n",
      "        0.6483, 0.4980, 0.4594, 0.4871, 0.5271, 0.3379, 0.4190, 0.4767, 0.4787,\n",
      "        0.4456, 0.4653, 0.4682, 0.3908, 0.6633, 0.4467, 0.4588, 0.6135, 0.5465,\n",
      "        0.5118, 0.6047, 0.5102, 0.4998, 0.4267, 0.3923, 0.4385, 0.3808, 0.4170,\n",
      "        0.4971, 0.6592, 0.4099, 0.4914, 0.6604, 0.6323, 0.5086, 0.4859, 0.6718,\n",
      "        0.6379, 0.4870, 0.4483, 0.6487, 0.5137, 0.4156, 0.3781, 0.6055, 0.4464,\n",
      "        0.5662, 0.5695, 0.5801, 0.5050, 0.4872, 0.5132, 0.5812, 0.5642, 0.4904,\n",
      "        0.5428, 0.5232, 0.4230, 0.4960, 0.6477, 0.3656, 0.4371, 0.3820, 0.3926,\n",
      "        0.5194, 0.4064, 0.5204, 0.4346, 0.3515, 0.5962, 0.6205, 0.4656, 0.4659,\n",
      "        0.4451, 0.5256, 0.6181, 0.4367, 0.5018, 0.4699, 0.4894, 0.3785, 0.4450,\n",
      "        0.4393, 0.4242, 0.5196, 0.4645, 0.3617, 0.4533, 0.4131, 0.4347, 0.3733,\n",
      "        0.4488, 0.4764, 0.6448, 0.4057, 0.5220, 0.5676, 0.6092, 0.5404, 0.4885,\n",
      "        0.4968, 0.5361, 0.5422, 0.3971, 0.3980, 0.4603, 0.4166, 0.5147, 0.6165,\n",
      "        0.6042, 0.4944, 0.6463, 0.4449, 0.5233, 0.5009, 0.3849, 0.4092, 0.3895,\n",
      "        0.4530, 0.4314, 0.6137, 0.5075, 0.5653, 0.5307, 0.4028, 0.5583, 0.6358,\n",
      "        0.3713, 0.4584, 0.5094, 0.5250, 0.3534, 0.5332, 0.5018, 0.6084, 0.4758,\n",
      "        0.3932, 0.4488, 0.4814, 0.4848, 0.4545, 0.5278, 0.5140, 0.6215, 0.5463,\n",
      "        0.4050, 0.5213, 0.4367, 0.5656, 0.4063, 0.5867, 0.4949, 0.4167, 0.5856,\n",
      "        0.6635, 0.5309, 0.6143, 0.5275, 0.4809, 0.5249, 0.5618, 0.5162, 0.6393,\n",
      "        0.4035, 0.5831, 0.4850, 0.5023, 0.3944, 0.4514, 0.6288, 0.3712, 0.3806,\n",
      "        0.4463, 0.5545, 0.4901, 0.6064, 0.3864, 0.4056, 0.6230, 0.5738, 0.4389,\n",
      "        0.4166, 0.4754, 0.3703, 0.4691, 0.3775, 0.4388, 0.4008, 0.4629, 0.5710,\n",
      "        0.4983, 0.5225, 0.5453, 0.5636, 0.4868, 0.4495, 0.5853, 0.3661, 0.6001,\n",
      "        0.6526, 0.6579, 0.6190, 0.6456, 0.5179, 0.6623, 0.4358, 0.5506, 0.6328,\n",
      "        0.4488, 0.5285, 0.5816, 0.4464, 0.4564, 0.4782, 0.4464, 0.5125, 0.3545,\n",
      "        0.5393, 0.6644, 0.5726, 0.4943, 0.5284, 0.5289, 0.6432, 0.5934, 0.6495,\n",
      "        0.5338, 0.5491, 0.6585, 0.6571, 0.6425, 0.6278, 0.4922, 0.6460, 0.5298,\n",
      "        0.6554, 0.6611, 0.6235, 0.6686, 0.5730, 0.6223, 0.6583, 0.6481, 0.5615,\n",
      "        0.6693, 0.5778, 0.6651, 0.6643, 0.4837, 0.6099, 0.5738, 0.6220, 0.4011,\n",
      "        0.6067, 0.4408, 0.6628, 0.6154, 0.6178, 0.4284, 0.4019, 0.4641, 0.5888,\n",
      "        0.6562, 0.4614, 0.4129, 0.6508, 0.3713, 0.4748, 0.4913, 0.4666, 0.4979,\n",
      "        0.3523, 0.5796, 0.3888, 0.4145, 0.6125, 0.6711, 0.6660, 0.4828, 0.4941,\n",
      "        0.4514, 0.4852, 0.3793, 0.4977, 0.4474, 0.4118, 0.4364, 0.4068, 0.4972,\n",
      "        0.4557, 0.3694, 0.4833, 0.4826, 0.6280, 0.3721, 0.3497, 0.5859, 0.4620,\n",
      "        0.6106, 0.6527, 0.6659, 0.4688, 0.5550, 0.3063, 0.6599, 0.6145, 0.4557,\n",
      "        0.6584, 0.4293, 0.4898, 0.4663, 0.5044, 0.4465, 0.4276, 0.4117, 0.3958,\n",
      "        0.4271, 0.4001, 0.3563, 0.5181, 0.4461, 0.5515, 0.3476, 0.4197, 0.6415,\n",
      "        0.4799, 0.4323, 0.5860, 0.4761, 0.4281, 0.5824, 0.4886, 0.4938, 0.3732,\n",
      "        0.6091, 0.4611, 0.6629, 0.6548, 0.3964, 0.3866, 0.5040, 0.6016, 0.6609,\n",
      "        0.5574, 0.5738, 0.3484, 0.6422, 0.3442, 0.4803, 0.6303, 0.3385, 0.4935,\n",
      "        0.5661, 0.6646, 0.5726, 0.3877, 0.6518, 0.4569, 0.3212, 0.3333, 0.4055,\n",
      "        0.6511, 0.6377, 0.5039, 0.6015, 0.6352, 0.6308, 0.6417, 0.4491, 0.6682,\n",
      "        0.6099, 0.5645, 0.4043, 0.3433, 0.3542, 0.3584, 0.6067, 0.6094, 0.5596,\n",
      "        0.3390, 0.4320, 0.6550, 0.6604, 0.6552, 0.6579, 0.4995, 0.3858, 0.3753,\n",
      "        0.6656, 0.4716, 0.4819, 0.4952, 0.4792, 0.4850, 0.4061, 0.5192, 0.5023,\n",
      "        0.3735, 0.6380, 0.3657, 0.5590, 0.5910, 0.6656, 0.3758, 0.6336, 0.6353,\n",
      "        0.6329, 0.4910, 0.4451, 0.3904, 0.3760, 0.4290, 0.4845, 0.6453, 0.4872],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Predictive entropy on youtube comments test data\n",
    "ent = dirichlet_entropy(youtube_alpha_test)\n",
    "print(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "46e3e41f-12f3-4e57-b39c-7ee634fbe236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5143, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(ent.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
